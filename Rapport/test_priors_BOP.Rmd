---
title: "Tentative de borrow avec le BOP2"
author: "Guillaume Mulier, Lucie Biard, Vincent Levy"
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: yes
    theme: sandstone
    number_sections: yes
    code_folding: hide
    toc_float: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.width = 8,
                      fig.height = 6)
```

```{r pkg-import, include = FALSE}
library(tidyverse)
here::i_am("Rapport/test_priors_BOP.Rmd")
library(here)
library(knitr)
library(rlang)
library(flextable)
library(readxl)
library(patchwork)
library(ggtext)

theme_set(theme_light(base_size = 14) +
            theme(strip.background = element_rect(fill = "white", color = "black", size = 1.2),
                  strip.text = element_text(face = "bold", color = "black")))
```

```{r data-processing}
## Analyse principale
CaracGlobales <- list()
CaracBras <- list()
CaracEssais <- list()
walk(1:6, \(fich_num) {
  Fichiers <- paste0("Data/SimuPpal20250611/resultats_priorsppal_20250611_", 1:6, ".RData")
  fichier_temp <- Fichiers[fich_num]
  load(here(fichier_temp), envir = current_env())
  assign("CaracGlobales", append(CaracGlobales, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[1]]))))), global_env())
  assign("CaracBras", append(CaracBras, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[2]]))))), global_env())
  assign("CaracEssais", append(CaracEssais, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[4]]))))), global_env())
})
CaracGlobales <- do.call("rbind", CaracGlobales)
CaracGlobales$methode[CaracGlobales$methode == "mBOP"] <- "mBOP_both"
CaracGlobales$methode[CaracGlobales$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracGlobales <- separate(CaracGlobales, methode, c("methode", "cible"), "_")
CaracBras <- do.call("rbind", CaracBras)
CaracBras$methode[CaracBras$methode == "mBOP"] <- "mBOP_both"
CaracBras$methode[CaracBras$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracBras <- separate(CaracBras, methode, c("methode", "cible"), "_")
CaracEssais <- do.call("rbind", CaracEssais)
CaracEssais$methode[CaracEssais$methode == "mBOP"] <- "mBOP_both"
CaracEssais$methode[CaracEssais$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracEssais <- separate(CaracEssais, methode, c("methode", "cible"), "_")
CaracEssais$larg_ic_eff <- CaracEssais$icsup_eff - CaracEssais$icinf_eff
CaracEssais$larg_ic_tox <- CaracEssais$icsup_tox - CaracEssais$icinf_tox
CaracGlobales$n_bras <- "3 arms"
CaracBras$n_bras <- "3 arms"
CaracEssais$n_bras <- "3 arms"

## Sensibilité : 4 bras
CaracGlobales4Bras <- list()
CaracBras4Bras <- list()
CaracEssais4Bras <- list()
walk(1:6, \(fich_num) {
  Fichiers <- paste0("Data/SimuSensi20250611/resultats_priorssens4_20250611_", 1:6, ".RData")
  fichier_temp <- Fichiers[fich_num]
  load(here(fichier_temp), envir = current_env())
  assign("CaracGlobales4Bras", append(CaracGlobales4Bras, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[1]]))))), global_env())
  assign("CaracBras4Bras", append(CaracBras4Bras, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[2]]))))), global_env())
  assign("CaracEssais4Bras", append(CaracEssais4Bras, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[4]]))))), global_env())
})
CaracGlobales4Bras <- do.call("rbind", CaracGlobales4Bras)
CaracGlobales4Bras$methode[CaracGlobales4Bras$methode == "mBOP"] <- "mBOP_both"
CaracGlobales4Bras$methode[CaracGlobales4Bras$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracGlobales4Bras <- separate(CaracGlobales4Bras, methode, c("methode", "cible"), "_")
CaracBras4Bras <- do.call("rbind", CaracBras4Bras)
CaracBras4Bras$methode[CaracBras4Bras$methode == "mBOP"] <- "mBOP_both"
CaracBras4Bras$methode[CaracBras4Bras$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracBras4Bras <- separate(CaracBras4Bras, methode, c("methode", "cible"), "_")
CaracEssais4Bras <- do.call("rbind", CaracEssais4Bras)
CaracEssais4Bras$methode[CaracEssais4Bras$methode == "mBOP"] <- "mBOP_both"
CaracEssais4Bras$methode[CaracEssais4Bras$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracEssais4Bras <- separate(CaracEssais4Bras, methode, c("methode", "cible"), "_")
CaracEssais4Bras$larg_ic_eff <- CaracEssais4Bras$icsup_eff - CaracEssais4Bras$icinf_eff
CaracEssais4Bras$larg_ic_tox <- CaracEssais4Bras$icsup_tox - CaracEssais4Bras$icinf_tox
CaracGlobales4Bras$n_bras <- "4 arms"
CaracBras4Bras$n_bras <- "4 arms"
CaracEssais4Bras$n_bras <- "4 arms"

## Sensibilité : 5 bras
CaracGlobales5Bras <- list()
CaracBras5Bras <- list()
CaracEssais5Bras <- list()
walk(1:6, \(fich_num) {
  Fichiers <- paste0("Data/SimuSensi20250611/resultats_priorssens5_20250611_", 1:6, ".RData")
  fichier_temp <- Fichiers[fich_num]
  load(here(fichier_temp), envir = current_env())
  assign("CaracGlobales5Bras", append(CaracGlobales5Bras, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[1]]))))), global_env())
  assign("CaracBras5Bras", append(CaracBras5Bras, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[2]]))))), global_env())
  assign("CaracEssais5Bras", append(CaracEssais5Bras, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[4]]))))), global_env())
})
CaracGlobales5Bras <- do.call("rbind", CaracGlobales5Bras)
CaracGlobales5Bras$methode[CaracGlobales5Bras$methode == "mBOP"] <- "mBOP_both"
CaracGlobales5Bras$methode[CaracGlobales5Bras$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracGlobales5Bras <- separate(CaracGlobales5Bras, methode, c("methode", "cible"), "_")
CaracBras5Bras <- do.call("rbind", CaracBras5Bras)
CaracBras5Bras$methode[CaracBras5Bras$methode == "mBOP"] <- "mBOP_both"
CaracBras5Bras$methode[CaracBras5Bras$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracBras5Bras <- separate(CaracBras5Bras, methode, c("methode", "cible"), "_")
CaracEssais5Bras <- do.call("rbind", CaracEssais5Bras)
CaracEssais5Bras$methode[CaracEssais5Bras$methode == "mBOP"] <- "mBOP_both"
CaracEssais5Bras$methode[CaracEssais5Bras$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracEssais5Bras <- separate(CaracEssais5Bras, methode, c("methode", "cible"), "_")
CaracEssais5Bras$larg_ic_eff <- CaracEssais5Bras$icsup_eff - CaracEssais5Bras$icinf_eff
CaracEssais5Bras$larg_ic_tox <- CaracEssais5Bras$icsup_tox - CaracEssais5Bras$icinf_tox
CaracGlobales5Bras$n_bras <- "5 arms"
CaracBras5Bras$n_bras <- "5 arms"
CaracEssais5Bras$n_bras <- "5 arms"

## Sensibilité aux priors
CaracGlobalesPriors <- list()
CaracBrasPriors <- list()
CaracEssaisPriors <- list()
walk(1:6, \(fich_num) {
  Fichiers <- paste0("Data/SimuSensi20250611/resultats_priorssensprio_20250611_", 1:6, ".RData")
  fichier_temp <- Fichiers[fich_num]
  load(here(fichier_temp), envir = current_env())
  assign("CaracGlobalesPriors", append(CaracGlobalesPriors, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[1]]))))), global_env())
  assign("CaracBrasPriors", append(CaracBrasPriors, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[2]]))))), global_env())
  assign("CaracEssaisPriors", append(CaracEssaisPriors, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[4]]))))), global_env())
})
CaracGlobalesPriors <- do.call("rbind", CaracGlobalesPriors)
CaracBrasPriors <- do.call("rbind", CaracBrasPriors)
CaracEssaisPriors <- do.call("rbind", CaracEssaisPriors)
CaracEssaisPriors$larg_ic_eff <- CaracEssaisPriors$icsup_eff - CaracEssaisPriors$icinf_eff
CaracEssaisPriors$larg_ic_tox <- CaracEssaisPriors$icsup_tox - CaracEssaisPriors$icinf_tox

## Modèle logistique en fonction de log(d/d*)
CaracGlobalesLogit <- list()
CaracBrasLogit <- list()
CaracEssaisLogit <- list()
walk(1:2, \(fich_num) {
  Fichiers <- paste0("Data/SimuLogistique20250611/resultats_priorslog_20250611_", 1:2, ".RData")
  fichier_temp <- Fichiers[fich_num]
  load(here(fichier_temp), envir = current_env())
  assign("CaracGlobalesLogit", append(CaracGlobalesLogit, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[1]]))))), global_env())
  assign("CaracBrasLogit", append(CaracBrasLogit, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[2]]))))), global_env())
  assign("CaracEssaisLogit", append(CaracEssaisLogit, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[4]]))))), global_env())
})
CaracGlobalesLogit <- do.call("rbind", CaracGlobalesLogit)
CaracGlobalesLogit$methode[CaracGlobalesLogit$methode == "mBOP"] <- "mBOP_both"
CaracGlobalesLogit$methode[CaracGlobalesLogit$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracGlobalesLogit <- separate(CaracGlobalesLogit, methode, c("methode", "cible"), "_")
CaracBrasLogit <- do.call("rbind", CaracBrasLogit)
CaracBrasLogit$methode[CaracBrasLogit$methode == "mBOP"] <- "mBOP_both"
CaracBrasLogit$methode[CaracBrasLogit$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracBrasLogit <- separate(CaracBrasLogit, methode, c("methode", "cible"), "_")
CaracEssaisLogit <- do.call("rbind", CaracEssaisLogit)
CaracEssaisLogit$methode[CaracEssaisLogit$methode == "mBOP"] <- "mBOP_both"
CaracEssaisLogit$methode[CaracEssaisLogit$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracEssaisLogit <- separate(CaracEssaisLogit, methode, c("methode", "cible"), "_")
CaracEssaisLogit$larg_ic_eff <- CaracEssaisLogit$icsup_eff - CaracEssaisLogit$icinf_eff
CaracEssaisLogit$larg_ic_tox <- CaracEssaisLogit$icsup_tox - CaracEssaisLogit$icinf_tox
CaracGlobalesLogit$n_bras <- "3 arms"
CaracBrasLogit$n_bras <- "3 arms"
CaracEssaisLogit$n_bras <- "3 arms"
CaracGlobalesLogit$methode <- paste0("ver", CaracGlobalesLogit$methode)
CaracBrasLogit$methode <- paste0("ver", CaracBrasLogit$methode)
CaracEssaisLogit$methode <- paste0("ver", CaracEssaisLogit$methode)
CaracGlobalesLogit <- bind_rows(CaracGlobalesLogit, CaracGlobales %>% filter(methode %in% c("log1BOP", "log2BOP")))
CaracBrasLogit <- bind_rows(CaracBrasLogit, CaracBras %>% filter(methode %in% c("log1BOP", "log2BOP")))
CaracEssaisLogit <- bind_rows(CaracEssaisLogit, CaracEssais %>% filter(methode %in% c("log1BOP", "log2BOP")))

# CRM-like models
CaracGlobalesCrm <- list()
CaracBrasCrm <- list()
CaracEssaisCrm <- list()
walk(1:3, \(fich_num) {
  Fichiers <- paste0("Data/SimuSensi20250611/resultats_priorssenscrm_20250611_", 1:3, ".RData")
  fichier_temp <- Fichiers[fich_num]
  load(here(fichier_temp), envir = current_env())
  assign("CaracGlobalesCrm", append(CaracGlobalesCrm, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[1]]))))), global_env())
  assign("CaracBrasCrm", append(CaracBrasCrm, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[2]]))))), global_env())
  assign("CaracEssaisCrm", append(CaracEssaisCrm, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[4]]))))), global_env())
})
CaracGlobalesCrm <- do.call("rbind", CaracGlobalesCrm)
CaracGlobalesCrm$methode[CaracGlobalesCrm$methode == "mBOP"] <- "mBOP_both"
CaracGlobalesCrm$methode[CaracGlobalesCrm$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracGlobalesCrm <- separate(CaracGlobalesCrm, methode, c("methode", "cible"), "_")
CaracBrasCrm <- do.call("rbind", CaracBrasCrm)
CaracBrasCrm$methode[CaracBrasCrm$methode == "mBOP"] <- "mBOP_both"
CaracBrasCrm$methode[CaracBrasCrm$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracBrasCrm <- separate(CaracBrasCrm, methode, c("methode", "cible"), "_")
CaracEssaisCrm <- do.call("rbind", CaracEssaisCrm)
CaracEssaisCrm$methode[CaracEssaisCrm$methode == "mBOP"] <- "mBOP_both"
CaracEssaisCrm$methode[CaracEssaisCrm$methode == "Simon+Iva"] <- "Simon+Iva_both"
CaracEssaisCrm <- separate(CaracEssaisCrm, methode, c("methode", "cible"), "_")
CaracEssaisCrm$larg_ic_eff <- CaracEssaisCrm$icsup_eff - CaracEssaisCrm$icinf_eff
CaracEssaisCrm$larg_ic_tox <- CaracEssaisCrm$icsup_tox - CaracEssaisCrm$icinf_tox
CaracGlobalesCrm$n_bras <- "3 arms"
CaracBrasCrm$n_bras <- "3 arms"
CaracEssaisCrm$n_bras <- "3 arms"
```


```{css, echo = FALSE}
.caption {
  font-weight: bold;
  font-size: medium;
}
```


# Les différents modèles

## BOP2 : "mBOP"

La 1^ère^ façon d'analyser est le BOP2 classique qu'on applique à un essai multi-bras : 

- stop pour futilité si $Pr(\pi_\text{eff}\leq\phi_\text{eff}|D_n)>C_n$
- stop pour toxicité si $Pr(\pi_\text{tox}>\phi_\text{tox}|D_n)>C_n$

avec $\phi_\text{eff}$ et $\phi_\text{tox}$ qui sont déterminés par les hypothèses prises par les cliniciens.

Les probabilités a posteriori sont calculées avec des lois beta conjuguées :

$$
Pr(\pi|D_n)=Beta(a_0+x,b_0+n-x)
$$

avec $a_0$ et $b_0$ les paramètres du prior, $x$ et $n$ les nombres d'évènements et de patients dans le bras d'intérêt.


## BOP2 avec power prior : "powBOP"

En 2^ème^ choix, j'ai choisi de combiner le BOP2 avec le power prior d'Ibrahim et Chen avec un exposant qui est une constante.
Cela a été appliqué à la toxicité uniquement, ou à l'efficacité et la toxicité.

La probabilité a posteriori s'écrit de la façon suivante :

$$
Pr(\pi|D_n)=Beta(a_0+x+a\times x_p,b_0+n-x+a\times(n_p-x_p))
$$

avec $x_p$ et $n_p$ le nombre de toxicités et de patients dans les autres bras qui ne sont pas significativement différents du bras d'intérêt ; et $a$ l'exposant du power prior.

Un exposant de 0.5 a été pris comme compromis entre le gain de puissance et le risque de faux positifs.


## BOP2 en utilisant un modèle hiérarchique pour la toxicité : "hBOP"

L'hypothèse derrière un modèle hiérarchique serait l'échangeabilité, ce qui est peu probable dans notre cas.
De ce que j'ai lu en faisant la biblio, souvent dans les basket trials, on utilise ce type de modèle en faisant l'hypothèse que l'efficacité d'un traitement sera la même dans toutes les indications par exemple.
Néanmoins, je pense que cela peut contribuer à diminuer la variance et donc avoir une meilleure précision autour de l'estimation de toxicité.

A noter que ce modèle est plus dur à estimer, et il y a des divergences en nombre variable selon les jeux de données.
J'ai essayé de les régler, mais il en reste un peu.

Le modèle est le suivant : 

$$
\mu \sim N(0, 5)\\
\sigma \sim N(0, 5) [\sigma > 0]\\
logit(p_1,p_2,...,p_K) \sim N(\mu,\sigma)\\
(x_1,x_2,...,x_K)\sim Binom((n_1,n_2,...,n_K),(p_1,p_2,...,p_K))
$$

Pour une raison qui m'échappe, la loi normale pour le paramètre de variance est meilleure que les autres distributions et donne moins de problèmes de convergence.

Dans la littérature, certains proposaient la loi de Cauchy, mais Gelmann est cité comme disant qu'une loi gamma ou une loi de Student tronquée positive est mieux adaptée.
Et on trouve aussi pas mal de loi normales tronquées.
En testant un peu, la loi normale donne moins de divergences.


## BOP2 en utilisant un modèle hiérarchique calibré pour la toxicité : "cbhmBOP"

Proposé par Chu et Yuan en 2018, l'idée est de mesurer le degré d'hétérogénéité entre les bras, et d'adapter le paramètre $\sigma$ du BHM en conséquence.
Ainsi, on estime un hyperparamètre de moins et c'est plus facile.
Une mesure classique d'hétérogénéité (et celle qui est prise ici) est la statistique du $\chi^2$.
Le fait de prendre une exponentielle pour la formule de la variance contraint des valeurs positives.

Les paramètres $a$ et $b$ ci-dessous sont calibrés par la procédure décrite dans l'article de Chu et Yuan.

Le modèle est le suivant : 

$$
\mu \sim N(0, 5)\\
\sigma^2 = e^{a+b\times\log(\text{Mesure d'hétérogénéité})}\\
logit(p_1,p_2,...,p_K) \sim N(\mu,\sigma)\\
(x_1,x_2,...,x_K)\sim Binom((n_1,n_2,...,n_K),(p_1,p_2,...,p_K))
$$


## BOP2 en analysant la toxicité par un modèle logistique : "bop_log1/2"

J'ai juste fait un modèle logistique simple avec comme seule covariable la dose.
Conformément à ce qui est écrit par Neuenschwander, la dose est remplacée par le ratio entre la dose du bras et la dose de référence (ici la dose 1).
Les doses sont donc des ratios 1, 2 et 3.

J'ai testé plusieurs versions du modèle logistique :

1. modèle log-linéaire avec la dose : 
$$
\alpha\sim N(0,5)\\
\beta\sim N(0,5)\\
y\sim \text{Bernoulli}(expit(\alpha+\beta\times\text{Dose}))
$$
2. modèle log-linéaire avec la dose avec une pente positive : 
$$
\alpha\sim N(0,5)\\
\beta\sim N(0,5) ; \beta\geq0\\
y\sim \text{Bernoulli}(expit(\alpha+\beta\times\text{Dose}))
$$
3. modèle log-linéaire avec la dose avec un prior positif sur la pente : 
$$
\alpha\sim N(0,5)\\
\beta\sim N(0.5,5)\\
y\sim \text{Bernoulli}(expit(\alpha+\beta\times\text{Dose}))
$$
4. modèle avec la dose en catégoriel (on a 3 doses, et on les considère dans leur ordre croissant) : 
$$
\alpha\sim N(0,5)\\
\beta_1\sim N(0,5)\\
\beta_2\sim N(0,5)\\
y\sim \text{Bernoulli}(expit(\alpha+\beta_1\times\text{Dose}\in [2,3]+\beta_2\times\text{Dose}\in [3]))
$$
5. même modèle que le modèle 4, mais on force les coefficients à être positifs (hypothèse de la relation croissante avec la dose) : 
$$
\alpha\sim N(0,5)\\
\beta_1\sim N(0,5) ; \beta_1\geq0\\
\beta_2\sim N(0,5) ; \beta_2\geq0\\
y\sim \text{Bernoulli}(expit(\alpha+\beta_1\times\text{Dose}\in [2,3]+\beta_2\times\text{Dose}\in [3]))
$$
6. modèle reprenant la dose en variable continue avec un term quadratique pour autoriser des relations non linéaires : 
$$
\alpha\sim N(0,5)\\
\beta\sim N(0,5)\\
\gamma\sim N(0,5)\\
y\sim \text{Bernoulli}(expit(\alpha+\beta\times\text{Dose}+\gamma\times\text{Dose}^2))
$$
Seuls les modèles 1 et 2 ont été réalisés.
Les modèles 4 et 6 avec 3 paramètres donnent des résultats similaires au mBOP.
Les modèles 5 donne comme le modèle 2 et le modèle 3 presque comme le modèle 1. 

## Simon + Ivanova

Analyse pour l'efficacité faite par schéma de Simon :

- analyse 1 à 29 patients : arrêt pour futilité si 11 ou moins réponses ;
- analyse finale à 58 patients : conclusion d'efficacité si plus de 20 réponses.

En parallèle, monitoring de la toxicité par la méthode d'Ivanova.
On stoppe l'essai si $Pr(p_\text{tox}>0.4|D_n)>0.5$.
Cela aboutit aux règles d'arrêt suivantes :

- analyse 1 à 29 patients : arrêt pour futilité si plus de 11 toxicités ;
- analyse finale à 58 patients : conclusion d'efficacité si 23 ou moins toxicités.


## Analyse jointe eff/tox

Aussi, j'ai décidé d'appliquer les modèles à l'efficacité et à la toxicité pour les variations du BOP2 avec partage d'information.


# Paramètres de simulations

J'ai simulé 5000 essais pour évaluer chaque scénario pour chaque méthode.

Paramètres d'optimisation du seuil (comme pour mBOP de notre article) :

- FWER = 0.1
- 10 000 essais simulés pour évaluer le seuil, puis 5 000 essais par scénario
- Analyses d'efficacité et de toxicité à 29/58 patients
- 3 bras de traitement
- les bras seraient 3 doses d'Ibrutinib : 140, 280, et 420 mg/jour
- $H_0:\pi_{eff}=0.30 ; \pi_{tox}=0.40$ soit $(0.15;0.15;0.25;0.45)$ ($R=0.13$)
- $H_1:\pi_{eff}=0.50;\pi_{tox}=0.30$ soit $(0.20;0.30;0.10;0.40)$ ($R=0.22$)

J'ai pris 10 scénarios en respectant l'hypothèse que l'efficacité et la toxicité sont croissantes avec la dose, avec possiblement des plateaux.
Ils sont représentés sur l'image ci-dessous :

```{r img-sc}
include_graphics(here("Figures/scenar_simul_v5_eng.png"))
```


# Résultats de la proportion de conclusion à un traitement prometteur

## Scénario 1

Ici tout les bras sont à l'hypothèse nulle.

```{r, fig.cap = "FWER pour le scénario 1"}
CaracGlobales %>%
  filter(scenar %in% c("Sc1")) %>%
  ggplot(aes(rejet_glob, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "FWER", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0)
```

Le FWER est respecté pour mBOP.
Il est autour de 9.5%.

On remarque la grande différence entre partage juste pour toxicité et partage pour efficacité et toxicité pour powBOP et log2BOP.
Globalement, le FWER est contrôlé sous le scénario nul global.


```{r, fig.cap = "Proportion d'essai prometteurs dans chaque bras pour le scénario 1"}
CaracBras %>%
  filter(scenar %in% c("Sc1")) %>%
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "FWER", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

Les rejets dans les bras sont comparables, sauf pour log2BOP qui rejette plus dans le bras 2 lorsqu'on partage pour efficacité et toxicité, et rejette plus dans le bras 1 avec un partage pour toxicité uniquement.


## Scénario 2

On est ici dans le cas où tous les bras sont à l'hypothèse nulle, mais avec une relation faiblement croissante.

```{r, fig.cap = "Puissance sous un scénario d'hypothèse nulle globale mais un peu croissante"}
CaracGlobales %>%
  filter(scenar %in% c("Sc2")) %>%
  ggplot(aes(rejet_glob, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "Puissance", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0)
```


```{r, fig.cap = "Puissance sous un scénario d'hypothèse nulle globale mais un peu croissante par bras"}
CaracBras %>%
  filter(scenar %in% c("Sc2")) %>%
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "Puissance", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

Les conclusions sont similaires à ce qu'on avait vu pour le scénario 1.


## Scénario 3

On a le scénario tout H1.

```{r, fig.cap = "Puissance sous un scénario d'hypothèse alternative globale"}
CaracGlobales %>%
  filter(scenar %in% c("Sc3")) %>%
  ggplot(aes(rejet_glob, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "Puissance", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0)
```

La puissance globale est très élevée.
Il faut regarder ce qu'il se passe dans les bras pour voir quelque chose.

```{r, fig.cap = "Puissance sous un scénario d'hypothèse alternative globale, dans chaque bras"}
CaracBras %>%
  filter(scenar %in% c("Sc3")) %>%
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "Puissance", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

```{r, eval = FALSE}
CaracEssais %>% filter(methode %in% c("mBOP", "powBOP"), scenar == "Sc3")
CaracEssais %>% filter(methode %in% c("mBOP", "powBOP"), scenar == "Sc3") %>% group_by(methode, cible, n_simu) %>% summarise(nb_accord = sum(nb_ana < 2)) %>% count(methode, cible, nb_accord)
```

Simon+Ivanova est un peu plus conservateur que mBOP.
Pour les méthodes de partage d'information, globalement, on est plus puissant que mBOP.
Les plus puissants sont hBOP et log1BOP, avec log1BOP qui est plus puissant à la dose 2.
Pour log2BOP, on favorise le bras 1 avec une relation décroissante.

## Scénario 4

C'est la même chose que le scénario 3 mais les probabilités d'efficacité et de toxicités sont légèrement croissantes.

```{r, fig.cap = "Puissance sous un scénario d'hypothèse alternative globale mais un peu croissante"}
CaracGlobales %>%
  filter(scenar %in% c("Sc4")) %>%
  ggplot(aes(rejet_glob, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "Puissance", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0)
```

La puissance est maintenant de 100% pour tous les schémas.

```{r, fig.cap = "Puissance sous un scénario d'hypothèse alternative globale mais un peu croissante, dans chaque bras"}
CaracBras %>%
  filter(scenar %in% c("Sc4")) %>%
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "Puissance", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

Les conclusions sont les mêmes.


## Scénario I1

La dose 1 est futile et les 2 autres sont prometteuses.

```{r, fig.cap = "Conclusion de traitement prometteur dans les bras du scénario I1"}
CaracBras %>%
  filter(scenar %in% c("ScI1")) %>%
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% conclusion de traitement prometteur", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

On retrouve Simon+Iva qui est un peu plus conservateur et un peu moins puissant que mBOP.

powBOP est plus puissant lorsqu'on ne partage que sur la toxicité, mais en partageant en plus sur l'efficacité, il y a inflation majeure du taux de faux positifs.

Pour les autres schémas, en ne partageant que sur la toxicité, pas d'inflation du risque de faux positifs, et augmentation de la puissance qui est moins importante pour cbhmBOP.
hBOP est plus constant que les logBOP dans son gain de puissance.
En partageant efficacité et toxicité, pour hBOP et logBOP on voit une inflation du taux de faux positifs dans le bras 1.

Il est à noter qu'on est un peu supérieur à 10% de faux positifs dans le bras 1 (autour de 15-17%).


```{r, fig.cap = "Estimation de l'efficacité et de la toxicité pour les modèles logistiques dans le scnéario I1 bras 3"}
(CaracEssais %>%
  filter(scenar %in% c("ScI1"), methode %in% c("log1BOP", "log2BOP", "hBOP"), ttt == "ttt3") %>%
  ggplot(aes(methode, est_eff, fill = cible)) +
  geom_boxplot() +
   labs(x = "Schéma", y = "Efficacité") +
   scale_fill_discrete(type = c("darkblue", "darkred"))) |
  (CaracEssais %>%
  filter(scenar %in% c("ScI1"), methode %in% c("log1BOP", "log2BOP", "hBOP"), ttt == "ttt3") %>%
  ggplot(aes(methode, est_tox, fill = cible)) +
  geom_boxplot() +
   labs(x = "Schéma", y = "Toxicité") +
   scale_fill_discrete(type = c("darkblue", "darkred")))

```

On a donc l'illustation que le modèle bop_log2 surestime plus la toxicité ce qui explique la perte de puissance dans le bras 3.
hBOP quant à lui est moins optimiste sur l'efficacité dans le bras 3, mais moins pessimiste sur la toxicité.

## Scénario I2

On a ici encore 2 bras prometteurs, avec le bras 3 qui est toxique.

```{r, fig.cap = "Conclusion de traitement dans les bras du scénario I2"}
CaracBras %>%
  filter(scenar %in% c("ScI2")) %>%
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% conclusion de traitement prometteur", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

On retrouve le comportement indésirable du power prior, mais qui cette fois-ci se fait même en ne partageant que sur la toxicité.
C'est compréhensible puisqu'on va ajouter de l'information de bras non toxiques à un bras toxique.

Simon+Iva a ici un taux de faux positifs un peu plus élevé que mBOP, mais comme j'ai optimisé les règles d'efficacité et de toxicité séparément, c'est certainement lié au choix de risque de faux positif fait pour efficacité et toxicité.

cbhmBOP est un chouilla plus puissant que mBOP et avec un petit peu plus de faux positifs ; mais très comparable à mBOP.
Les 3 autres schémas sont plus puissants au même niveau dans le bras 1, dans le bras 2 ce sont les modèles logistiques qui font mieux, et dans le bras 3, augmentation du risque de faux positifs par rapport à mBOP (hBOP > log1BOP > log2BOP).


## Scénario 5

On a un mix des scénarios I1 et I2 avec le bras 1 futile et le bras 3 toxique.

```{r, fig.cap = "Conclusion de traitement dans les bras du scénario 5"}
CaracBras %>%
  filter(scenar %in% c("Sc5")) %>%
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% conclusion de traitement prometteur", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

On a un mix entre les résultats des scénarios I1 et I2.

Pour powBOP, on a l'augmentation du risque de faux positifs (pour la dose futile, uniquement avec partage sur efficacité et toxicité).

Le cbhmBOP est proche de mBOP.

Pour logBOP et hBOP, on retrouve l'inflation du risque de faux positifs pour la dose futile si on partage l'information pour l'efficacité en plus.
Et dans le bras 3, on a le même ordre d'inflation du risque de faux positifs entre les 3 (hBOP > log1BOP > log2BOP).


## Scénario 6

C'est un scénario 5 plus difficile car le bras 1 a une efficacité intermédiaire au lieu d'insuffisante.

```{r, fig.cap = "Conclusion de traitement dans les bras du scénario 5"}
CaracBras %>%
  filter(scenar %in% c("Sc6")) %>%
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% conclusion de traitement prometteur", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

On retrouve globalement la même tendance.

powBOP a une plus grande augmentation du risque de faux positifs dans les bras 1 et 3.

Dans le bras 1, on a une augmentation du taux de faux positifs ou une augmentation de la puissance selon comment on veut classer la dose.


## Scénario 7

Les 3 doses sont efficaces, la dose 1 est prometteuse, la 2 a une toxicité intermédiaire et la 3 est toxique.

```{r, fig.cap = "Conclusion de traitement dans les bras du scénario 7"}
CaracBras %>%
  filter(scenar %in% c("Sc7")) %>%
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% conclusion de traitement prometteur", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

Dans le bras 1, par rapport à mBOP, il y a gain de puissance pour log2BOP.

Dans le bras 2, il y a augmentation du pourcentage de conclusion à un traitement prometteur avec les méthodes de partage d'information.

Et dans le bras 3, il y a inflation du risque de faux positifs pour hBOP et powBOP.
On a même diminution du risque de faux positifs pour log2BOP.

Les résultats sont globalement similaires entre partage sur efficacité et toxicité par rapport à juste toxicité.
C'est peut-être dû au fait que tous les bras ont la même efficacité et c'est la toxicité qui limite.

```{r, fig.cap = "Proportion d'arrêts pour toxicité dans les bras du scénario 7"}
CaracBras %>%
  filter(scenar %in% c("Sc7")) %>%
  mutate(pourcent_tox = arret_tox / arret) %>% 
  ggplot(aes(pourcent_tox, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% d'arrêt ayant pour raison la toxicité", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

## Scénario 8

C'est le scénario le plus difficile avec la dose 1 futile, la dose 3 toxique et la dose 2 qui a une efficacité et une toxicité intermédiaire.

```{r, fig.cap = "Conclusion de traitement dans les bras du scénario 8"}
CaracBras %>%
  filter(scenar %in% c("Sc8")) %>%
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% conclusion de traitement prometteur", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

Simon+Iva est plus conservateur que mBOP dans les cas où l'efficacité est plus faible que sous H~1~, mais donne plus de faux positifs lorsque le traitement est toxique.

powBOP montre encore une augmentation du risque de faux positifs par rapport à mBOP.

cbhmBOP est encore une fois très proche de mBOP.

Les 2 modèles logistiques augmentent un peu le risque de faux positif dans le bras 1, et augmentent le pourcentage de conclusion à un traitement prometteur pour le bras 2.
Dans le bras 3, log1BOP fait environ comme mBOP et log2BOP a un risque de faux positifs plus faible qui est vraisemblablement médié par l'estimation de la toxicité.

hBOP quant à lui augmente le risque de faux positif dans les bras 1 et 3.


# Supplément : les autres caractéristiques opérationnelles

## Le nombre moyen de patients

```{r}
CaracBrasSup <- CaracBras %>%
  bind_rows(CaracBras %>% filter(methode %in% c("mBOP", "Simon+Iva")) %>% mutate(cible = "tox")) %>%
  mutate(cible = ifelse(cible == "both", "efftox", cible))
```


```{r, fig.width = 10, fig.height = 16}
CaracBrasSup %>%
  mutate(scenar = factor(scenar)) %>%
  ggplot(aes(x = tot_pat, y = methode, fill = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 4.5, ymax = 5.5, fill = "darkgrey", alpha = .6) +
  geom_col(position = position_dodge(width = 1)) +
  facet_grid(scenar ~ cible) +
  labs(y = NULL, x = "Nb moyen de patients")
```

La zone grisée correspond à mBOP pour faciliter les comparaisons.

Simon+Iva recrute moins de patients que mBOP dans tous les scénarios. 
A confirmer avec les arrêts précoces, mais on dirait qu'il y a plus d'arrêts précoces avec les règles Simon.

Le power prior a plus de patients recrutés en moyenne, sauf dans le scénario 2 (scénario où tous les bras sont à l'hypothèse nulle et le partage d'information peut être bénéifique pour le power prior).

Le hBOP, recrute moins de patients sous H0 globale, mais sinon a tendance à recruter un peu plus de patients que mBOP, ou alors environ le même nombre de patients en moyenne.
Notamment dans les scénarios I1 et I2, hBOP recrute plus de patients dans le bras problématique.

Pour le CBHM, on recrute de manière comparable à hBOP pour les scénarios 1 et 2 à H~0~ globale.
Ensuite, pour les autres scénarios, le CBHM a l'air de recruter un peu moins de patients que mBOP dans les bras qu'il ne faut pas continuer.

Enfin, pour les modèles logistiques, pour l'hypothèse nulle globale, ils ont moins de patients que mBOP, mais log2BOP recrute moins de patients dans les bras extrêmes alors que pour log1BOP c'est plutôt le bras intermédiaire qui a un nombre moyen de patients plus faible.
Pour les autres scénarios, on a plus de patients par rapport à mBOP de manière générale.
Dans les scénarios toxiques, le nombre moyen de patients est plus faible pour logBOP.


## Estimation de l'efficacité

```{r}
Scenarios <- list(
  "Sc1"  = list(ttt1 = c(0.15, 0.15, 0.25, 0.45), ttt2 = c(0.15, 0.15, 0.25, 0.45), ttt3 = c(0.15, 0.15, 0.25, 0.45)),
  "Sc2"  = list(ttt1 = c(0.13, 0.12, 0.27, 0.48), ttt2 = c(0.15, 0.13, 0.27, 0.45), ttt3 = c(0.16, 0.14, 0.29, 0.41)),
  "Sc3"  = list(ttt1 = c(0.20, 0.30, 0.10, 0.40), ttt2 = c(0.20, 0.30, 0.10, 0.40), ttt3 = c(0.20, 0.30, 0.10, 0.40)),
  "Sc4"  = list(ttt1 = c(0.15, 0.35, 0.10, 0.40), ttt2 = c(0.17, 0.35, 0.11, 0.37), ttt3 = c(0.19, 0.36, 0.11, 0.34)),
  "ScI1" = list(ttt1 = c(0.10, 0.20, 0.15, 0.55), ttt2 = c(0.20, 0.30, 0.10, 0.40), ttt3 = c(0.19, 0.36, 0.11, 0.34)),
  "ScI2" = list(ttt1 = c(0.15, 0.35, 0.10, 0.40), ttt2 = c(0.18, 0.34, 0.12, 0.36), ttt3 = c(0.25, 0.30, 0.15, 0.30)),
  "Sc5"  = list(ttt1 = c(0.11, 0.19, 0.17, 0.53), ttt2 = c(0.20, 0.30, 0.10, 0.40), ttt3 = c(0.25, 0.30, 0.15, 0.30)),
  "Sc6"  = list(ttt1 = c(0.14, 0.26, 0.14, 0.46), ttt2 = c(0.20, 0.30, 0.10, 0.40), ttt3 = c(0.25, 0.30, 0.15, 0.30)),
  "Sc7"  = list(ttt1 = c(0.18, 0.32, 0.12, 0.38), ttt2 = c(0.22, 0.28, 0.15, 0.35), ttt3 = c(0.23, 0.27, 0.17, 0.33)),
  "Sc8"  = list(ttt1 = c(0.12, 0.18, 0.18, 0.52), ttt2 = c(0.17, 0.23, 0.18, 0.42), ttt3 = c(0.23, 0.27, 0.17, 0.33))
)
TabScenars <- do.call("rbind", lapply(names(Scenarios), \(nom_scenar) {
  do.call("rbind", lapply(names(Scenarios[[nom_scenar]]), \(nom_bras) {
    VecProba <- Scenarios[[nom_scenar]][[nom_bras]]
    data.frame("scenar" = nom_scenar, "ttt" = nom_bras, "eff_true" = VecProba[1] + VecProba[2], "tox_true" = VecProba[1] + VecProba[3])
  }))
}))
CaracEssaisSup <- CaracEssais %>%
  bind_rows(CaracEssais %>% filter(methode %in% c("mBOP", "Simon+Iva")) %>% mutate(cible = "tox")) %>%
  mutate(cible = ifelse(cible == "both", "efftox", cible))
```


```{r, fig.width = 12, fig.height = 20}
left_join(CaracEssaisSup, TabScenars, by = join_by(scenar, ttt)) %>%
  group_by(scenar, ttt, methode, cible) %>%
  summarise(biais_eff = mean(est_eff - eff_true), .groups = "drop") %>%
  ggplot(aes(biais_eff, methode, fill = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 4.5, ymax = 5.5, fill = "darkgrey", alpha = .6) +
  geom_hline(yintercept = seq(1.5, 6.5), linetype = "dashed", color = "darkgrey", linewidth = 1) +
  geom_col(position = position_dodge(width = 1)) +
  facet_grid(scenar ~ cible) +
  scale_x_continuous(labels = scales::percent_format()) +
  labs(x = "Biais absolu dans l'estimation de l'efficacité")
```

Sur le côté droit, comme on n'applique le modèle qu'à la toxicité, on ne voit pas grand chose.
Globalement, on sous-estime la valeur d'efficacité, ce qui est attendu car on peut s'arrêter pour futilité, ce qui biaise l'estimation vers le bas.
Simon+Iva sous-estime un peu moins l'efficacité il semble.

mBOP sous-estime toujours, et plus lors de doses futiles, ce qui est attendu avec les arrêts précoces pour futilité.

Sur le côté gauche, ce qui saute aux yeux c'est que le modèle log2BOP est très biaisé dans tous les scénarios, probablement provoqué par la contrainte d'une relation croissante avec la dose.
On a souvent une surestimation de l'efficacité dans les doses élevées et sous-estimée pour les doses faibles.
Pour le scénario I1, c'est le bras 2 qui est sous-estimé et les bras 1 et 3 qui sont surestimés en efficacité ; probablement à cause du fait que ce soit un scénario avec un OR non constant entre les doses.

Les power priors peuvent donner des biais dans les 2 sens selon le scénario.

Le modèle hiérarchique, en ramenant l'estimation vers la moyenne commune aux 3 bras, peut donner des biais dans les 2 sens (surestimation pour les faibles doses et sous-estimation pour les fortes doses), dans un ordre de grandeur qui est comparable à mBOP.

Le CBHM n'a presque pas de biais sauf dans les bras futiles pour lesquels il y a sous-estimation de l'efficacité.

Le modèle logistique 1 donne des résultats biaisés lorsque les OR ne sont pas proportionnels.

```{r, fig.width = 12, fig.height = 20}
CaracEssaisSup %>%
  mutate(larg_ic = icsup_eff - icinf_eff) %>%
  group_by(scenar, ttt, methode, cible) %>%
  summarise(moy = mean(larg_ic),
            perc5 = quantile(larg_ic, probs = .05),
            perc2_5 = quantile(larg_ic, probs = .025),
            perc95 = quantile(larg_ic, probs = .95),
            perc97_5 = quantile(larg_ic, probs = .975),
            .groups = "drop") %>%
  ggplot(aes(y = methode, color = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 4.5, ymax = 5.5, fill = "darkgrey", alpha = .6) +
  geom_hline(yintercept = seq(1.5, 6.5), linetype = "dashed", color = "darkgrey", linewidth = 1) +
  geom_point(aes(x = moy), position = position_dodge(width = 1)) +
  geom_segment(aes(x = perc2_5, xend = perc97_5), position = position_dodge(width = 1)) +
  facet_grid(scenar ~ cible) +
  scale_x_continuous(labels = scales::percent_format()) +
  labs(x = "Largeur de l'IC de l'efficacité", caption = "Le point est la moyenne et le trait va du 2.5ème percentile au 97.5ème percentile dans les 5000 essais simulés")
```

On se concentre encore sur le panel de gauche.

Le schéma de Simon+Iva donne globalement des IC pour l'efficacité plus larges (calculé par IC binomial exact).
cbhmBOP donne une largeur d'IC comparable à mBOP, et les autres méthodes de partages d'information vont globalement diminuer la largeur de l'IC.
Il est à noter que pour logBOP, la largeur de l'IC dépend de la dose.


## Estimation de la toxicité


```{r, fig.width = 12, fig.height = 20}
left_join(CaracEssaisSup, TabScenars, by = join_by(scenar, ttt)) %>%
  group_by(scenar, ttt, methode, cible) %>%
  summarise(biais_tox = mean(est_tox - tox_true), .groups = "drop") %>%
  ggplot(aes(biais_tox, methode, fill = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 4.5, ymax = 5.5, fill = "darkgrey", alpha = .6) +
  geom_hline(yintercept = seq(1.5, 6.5), linetype = "dashed", color = "darkgrey", linewidth = 1) +
  geom_col(position = position_dodge(width = 1)) +
  facet_grid(scenar ~ cible) +
  scale_x_continuous(labels = scales::percent_format()) +
  labs(x = "Biais absolu dans l'estimation de la toxicité")
```

Pour la toxicité, on a tendance à être biaisé vers une surrestimation de la toxicité de manière générale, ce qui va dans le sens de l'analyse : comme on arrête les bras trop toxiques, il y a des chances qu'on sélectionne des moments/des bras qui sont plus toxiques pour leur dernière analyse.

Les 2 panels sont comparables.

On remarque d'emblée qu'il y a des gros biais pour log2BOP avec une surestimation de la toxicité pour la dose la plus élevée, et une sous-estimation pour la dose la plus faible.
C'est certainement dû à la contrainte d'une relation positive avec la dose.

Pour le power prior, on peut être biaisé dans les 2 sens selon le scénario, avec de fortes valeurs de biais.

log1BOP est encore plus biaisé lorsque les OR ne sont pas proportionnels, mais garde un biais positif dans le cas d'OR proportionnel, sûrement avec les arrêts précoces.

Pour hBOP et cbhmBOP, l'amplitude du biais est variable selon les scénarios, avec hBOP qui sous-estime parfois la toxicité dans le bras 3, sûrement avec ramenant vers une moyenne commune les estimations de toxicité.

```{r, fig.width = 12, fig.height = 20}
CaracEssaisSup %>%
  mutate(larg_ic = icsup_tox - icinf_tox) %>%
  group_by(scenar, ttt, methode, cible) %>%
  summarise(moy = mean(larg_ic),
            perc5 = quantile(larg_ic, probs = .05),
            perc2_5 = quantile(larg_ic, probs = .025),
            perc95 = quantile(larg_ic, probs = .95),
            perc97_5 = quantile(larg_ic, probs = .975),
            .groups = "drop") %>%
  ggplot(aes(y = methode, color = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 7.5, ymax = 8.5, fill = "darkgrey", alpha = .6) +
  geom_hline(yintercept = seq(1.5, 6.5), linetype = "dashed", color = "darkgrey", linewidth = 1) +
  geom_point(aes(x = moy), position = position_dodge(width = 1)) +
  geom_segment(aes(x = perc2_5, xend = perc97_5), position = position_dodge(width = 1)) +
  facet_grid(scenar ~ cible) +
  scale_x_continuous(labels = scales::percent_format()) +
  labs(x = "Largeur de l'IC de la toxicité", caption = "Le point est la moyenne et le trait va du 2.5ème percentile au 97.5ème percentile dans les 5000 essais simulés")
```

Mêmes conclusions sur les IC que pour l'efficacité, avec cbhmBOP qui a un IC un peu moins large que mBOP.


## Raison d'arrêt

```{r, fig.height = 30}
CaracBrasSup %>% 
  mutate(arret_both = arret_fut + arret_tox - arret,
         arret_que_fut = arret_fut - arret_both,
         arret_que_tox = arret_tox - arret_both) %>% 
  select(methode, cible, scenar, ttt, rejet_h0, arret_both, arret_que_fut, arret_que_tox) %>% 
  pivot_longer(5:8) %>% 
  mutate(name = factor(name, levels = c("rejet_h0", "arret_both", "arret_que_fut", "arret_que_tox"), labels = c("Prometteur", "Futile+Toxique", "Futile", "Toxique")),
         ordonnee = paste0(methode, " - ", ttt)) %>% 
  ggplot(aes(value, ordonnee, fill = name)) +
  # annotate("ribbon", x = c(-Inf, Inf), ymin = 4.5, ymax = 5.5, fill = "darkgrey", alpha = .6) +
  # geom_hline(yintercept = seq(1.5, 6.5), linetype = "dashed", color = "darkgrey", linewidth = 1) +
  geom_col() +
  facet_grid(scenar ~ cible) +
  scale_x_continuous(labels = scales::percent_format()) +
  scale_fill_discrete(type = c("darkgreen", "#5206ba", "#a7b025", "#cd1e05")) +
  labs(x = "% de raison d'arrêt", y = NULL)
```

On a le mBOP qui rejette de façon équilibrée entre futilité/toxicité/les 2 pour les scénarios qui sont futiles et toxiques.
Pour les doses futiles ou toxiques, c'est surtout la bonne raison qui est la raison d'arrêt.

Pour Simon+Iva, on a moins d'arrêt pour les 2 raisons.
La règle de futilité étant plus conservatrice, il y a plus d'arrêt pour futilité.

powBOP, cbhmBOP et hBOP suivent la tendance du mBOP sur les raisons d'arrêt.

Pour log2BOP, on voit aussi qu'on rejette plus pour toxicité à une dose élevée.


# Analyse de sensibililté : scénarios 2, 4, I1 et I2 avec 4 et 5 doses étudiées.

Nous avons repris les scénarios 2 (H~0~ globale), 4 (H~1~ globale), I1 (dose 1 futile) et I2 (dernière dose toxique) pour comparer les résultats des différents modèles étudiés avec 3, 4 et 5 bras de traitements.

Ci-dessous les différents scénarios :

```{r}
Scenarios <- list(
  "Sc2"  = list(ttt1 = c(0.13, 0.12, 0.27, 0.48), ttt2 = c(0.15, 0.13, 0.27, 0.45), ttt3 = c(0.16, 0.14, 0.29, 0.41)),
  "Sc4"  = list(ttt1 = c(0.15, 0.35, 0.10, 0.40), ttt2 = c(0.17, 0.35, 0.11, 0.37), ttt3 = c(0.19, 0.36, 0.11, 0.34)),
  "ScI1" = list(ttt1 = c(0.10, 0.20, 0.15, 0.55), ttt2 = c(0.20, 0.30, 0.10, 0.40), ttt3 = c(0.19, 0.36, 0.11, 0.34)),
  "ScI2" = list(ttt1 = c(0.15, 0.35, 0.10, 0.40), ttt2 = c(0.18, 0.34, 0.12, 0.36), ttt3 = c(0.25, 0.30, 0.15, 0.30))
)
TabScenars3 <- do.call("rbind", lapply(names(Scenarios), \(nom_scenar) {
  do.call("rbind", lapply(names(Scenarios[[nom_scenar]]), \(nom_bras) {
    VecProba <- Scenarios[[nom_scenar]][[nom_bras]]
    data.frame("nb_bras" = "3 arms", "scenar" = nom_scenar, "ttt" = nom_bras, "eff_true" = VecProba[1] + VecProba[2], "tox_true" = VecProba[1] + VecProba[3])
  }))
}))
Scenarios <- list(
  "Sc2"  = list(ttt1 = c(0.12, 0.12, 0.28, 0.48), ttt2 = c(0.13, 0.13, 0.29, 0.45), ttt3 = c(0.15, 0.13, 0.29, 0.43), ttt4 = c(0.17, 0.13, 0.33, 0.37)),
  "Sc4"  = list(ttt1 = c(0.15, 0.35, 0.09, 0.41), ttt2 = c(0.16, 0.36, 0.10, 0.38), ttt3 = c(0.18, 0.36, 0.10, 0.36), ttt4 = c(0.20, 0.36, 0.10, 0.34)),
  "ScI1" = list(ttt1 = c(0.07, 0.18, 0.13, 0.62), ttt2 = c(0.10, 0.20, 0.15, 0.55), ttt3 = c(0.18, 0.32, 0.12, 0.38), ttt4 = c(0.19, 0.36, 0.11, 0.34)),
  "ScI2" = list(ttt1 = c(0.12, 0.38, 0.08, 0.42), ttt2 = c(0.16, 0.36, 0.09, 0.39), ttt3 = c(0.19, 0.35, 0.11, 0.35), ttt4 = c(0.25, 0.31, 0.15, 0.29))
)
TabScenars4 <- do.call("rbind", lapply(names(Scenarios), \(nom_scenar) {
  do.call("rbind", lapply(names(Scenarios[[nom_scenar]]), \(nom_bras) {
    VecProba <- Scenarios[[nom_scenar]][[nom_bras]]
    data.frame("nb_bras" = "4 arms", "scenar" = nom_scenar, "ttt" = nom_bras, "eff_true" = VecProba[1] + VecProba[2], "tox_true" = VecProba[1] + VecProba[3])
  }))
}))
Scenarios <- list(
  "Sc2"  = list(ttt1 = c(0.11, 0.11, 0.29, 0.49), ttt2 = c(0.13, 0.11, 0.29, 0.47), ttt3 = c(0.14, 0.12, 0.30, 0.44), ttt4 = c(0.15, 0.13, 0.31, 0.41), ttt5 = c(0.17, 0.13, 0.31, 0.39)),
  "Sc4"  = list(ttt1 = c(0.13, 0.37, 0.09, 0.41), ttt2 = c(0.15, 0.36, 0.09, 0.40), ttt3 = c(0.16, 0.36, 0.10, 0.38), ttt4 = c(0.18, 0.35, 0.10, 0.37), ttt5 = c(0.19, 0.35, 0.11, 0.35)),
  "ScI1" = list(ttt1 = c(0.08, 0.17, 0.16, 0.59), ttt2 = c(0.10, 0.20, 0.16, 0.54), ttt3 = c(0.17, 0.33, 0.11, 0.39), ttt4 = c(0.19, 0.34, 0.11, 0.36), ttt5 = c(0.19, 0.36, 0.11, 0.34)),
  "ScI2" = list(ttt1 = c(0.12, 0.38, 0.08, 0.42), ttt2 = c(0.14, 0.37, 0.08, 0.41), ttt3 = c(0.16, 0.36, 0.09, 0.39), ttt4 = c(0.19, 0.34, 0.11, 0.36), ttt5 = c(0.25, 0.29, 0.15, 0.31))
)
TabScenars5 <- do.call("rbind", lapply(names(Scenarios), \(nom_scenar) {
  do.call("rbind", lapply(names(Scenarios[[nom_scenar]]), \(nom_bras) {
    VecProba <- Scenarios[[nom_scenar]][[nom_bras]]
    data.frame("nb_bras" = "5 arms", "scenar" = nom_scenar, "ttt" = nom_bras, "eff_true" = VecProba[1] + VecProba[2], "tox_true" = VecProba[1] + VecProba[3])
  }))
}))
TabScenarRegroup <- bind_rows(TabScenars3, TabScenars4, TabScenars5)
```

```{r}
TabScenarRegroup %>% 
  mutate(scenar = factor(scenar, 
                         levels = c(paste0("Sc", c(2, 4)), "ScI1", "ScI2"))) %>%
  mutate(efficacite = case_when(eff_true < .31 ~ "futile",
                                eff_true < .5 ~ "intermediaire",
                                TRUE ~ "efficace"),
         toxicite = case_when(tox_true < .31 ~ "non toxique",
                                tox_true < .4 ~ "intermediaire",
                                TRUE ~ "toxique"),
         couleur = case_when(efficacite == "efficace" & toxicite == "non toxique" ~ "Promising",
                             efficacite == "futile" & toxicite == "toxique" ~ "Stopping",
                             efficacite == "futile" ~ "Stopping",
                             toxicite == "toxique" ~ "Stopping",
                             TRUE ~ "Intermediate"),
         bras = gsub("ttt", "D", ttt)) %>% 
  ggplot(aes(bras, group = nb_bras)) +
  geom_line(aes(y = eff_true, color = "Efficacy")) +
  geom_point(aes(y = eff_true, color = "Efficacy", shape = couleur), size = 3) +
  geom_line(aes(y = tox_true, color = "Toxicity")) +
  geom_point(aes(y = tox_true, color = "Toxicity", shape = couleur), size = 3) +
  facet_grid(nb_bras ~ scenar, scales = "free_x") +
  expand_limits(y = 0) +
  scale_color_discrete(type = c("darkblue", "darkred")) +
  scale_shape_manual(values = c(17, 15, 19)) +
  labs(x = "Treatment dosis", y = "Probability", color = "Endpoint", shape = "Decision")
```

En ce qui concerne les modèles, ce sont les mêmes que pour l'analyse principale.

```{r}
CaracGlobalesSensiBras <- rbind(CaracGlobales %>% filter(scenar %in% c("Sc2", "Sc4", "ScI1", "ScI2")), CaracGlobales4Bras, CaracGlobales5Bras)
CaracBrasSensiBras <- rbind(CaracBras %>% filter(scenar %in% c("Sc2", "Sc4", "ScI1", "ScI2")), CaracBras4Bras, CaracBras5Bras)
CaracEssaisSensiBras <- rbind(CaracEssais %>% filter(scenar %in% c("Sc2", "Sc4", "ScI1", "ScI2")), CaracEssais4Bras, CaracEssais5Bras)
```


## Proportion de conclusion à un traitement prometteur

### Scénario 2

```{r, fig.cap = "FWER pour le scénario 2 selon le nombre de bras", fig.width = 10}
CaracGlobalesSensiBras %>%
  filter(scenar %in% c("Sc2")) %>%
  ggplot(aes(rejet_glob, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "FWER", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(n_bras)) +
  scale_x_continuous(labels = scales::percent_format())
```

Les méthodes de partage d'information ont l'air plus conservatrices en augmentant le nombre de bras, ce qui semble logique puisqu'on a plus d'information à disposition.

Ci-dessous les résultats dans chaque bras, avec les partages d'information pour efficacité et toxicité :

```{r, fig.cap = "Proportion de conclusion à un traitement prometteur dans chaque bras pour le scénario 2 selon le nombre de bras"}
CaracBrasSensiBras %>%
  filter(cible %in% c("efftox", "both"), scenar == "Sc2") %>%
  ggplot(aes(ttt, rejet_h0, group = n_bras, color = n_bras)) +
  geom_point(size = 2) +
  geom_line() +
  facet_wrap(vars(methode)) +
  labs(x = "Dose", y = "Proportion de conclusion à un traitement prometteur", color = "# bras") +
  scale_color_discrete(type = c("black", "darkblue", "darkred")) +
  expand_limits(x = 0) +
  scale_y_continuous(labels = scales::percent_format())
```

Globalement, on est plus conservateur dans les bras, ce qui est attendu puisqu'on veut contrôler le FWER donc avec plus de bras on est plus strict.

Pour le powBOP, on est très conservateur ici en augmentant le nombre de bras.

### Scénario 4

```{r, fig.cap = "Puissance pour le scénario 2 selon le nombre de bras", fig.width = 10}
CaracGlobalesSensiBras %>%
  filter(scenar %in% c("Sc4")) %>%
  ggplot(aes(rejet_glob, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "Puissance", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Pas de partage", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(n_bras)) +
  scale_x_continuous(labels = scales::percent_format())
```

Ici, au global on ne voit pas grand-chose.

Ci-dessous les résultats dans chaque bras, avec les partages d'information pour efficacité et toxicité :

```{r, fig.cap = "Proportion de conclusion à un traitement prometteur dans chaque bras pour le scénario 4 selon le nombre de bras"}
CaracBrasSensiBras %>%
  filter(cible %in% c("efftox", "both"), scenar == "Sc4") %>%
  ggplot(aes(ttt, rejet_h0, group = n_bras, color = n_bras)) +
  geom_point(size = 2) +
  geom_line() +
  facet_wrap(vars(methode)) +
  labs(x = "Dose", y = "Proportion de conclusion à un traitement prometteur", color = "# bras") +
  scale_color_discrete(type = c("black", "darkblue", "darkred")) +
  expand_limits(y = 0) +
  scale_y_continuous(labels = scales::percent_format())
```

Simon+Iva est moins puissant dans ce scénario que mBOP.

On remarque la similitude entre mBOP et cbhmBOP comme pour les scénarios avec 3 bras.

powBOP est à 100% dans chaque bras.

log1BOP et log2BOP ont l'air de gagner en puissance par rapport à mBOP, mais avec un niveau équivalent dans le dernier bras.

### Scénario I1

A 3 bras, la 1^ère^ dose est futile, et à 4-5 bras, ce sont les 2 premières doses.

Ci-dessous les résultats dans chaque bras, avec les partages d'information pour efficacité et toxicité :

```{r, fig.cap = "Proportion de conclusion à un traitement prometteur dans chaque bras pour le scénario I1 selon le nombre de bras"}
CaracBrasSensiBras %>%
  filter(cible %in% c("efftox", "both"), scenar == "ScI1") %>%
  ggplot(aes(ttt, rejet_h0, group = n_bras, color = n_bras)) +
  geom_point(size = 2) +
  geom_line() +
  facet_wrap(vars(methode)) +
  labs(x = "Dose", y = "Proportion de conclusion à un traitement prometteur", color = "# bras") +
  scale_color_discrete(type = c("black", "darkblue", "darkred")) +
  expand_limits(y = 0) +
  scale_y_continuous(labels = scales::percent_format())
```

Simon+Iva est moins puissant dans ce scénario que mBOP sauf dans la dernière dose à 4 bras, et il est plus conservateur.

On remarque la similitude entre mBOP et cbhmBOP comme pour les scénarios avec 3 bras.

powBOP est très élevé dans chaque bras, avec donc un risque majeur de faux positifs.

hBOP semble corriger un peu son taux de faux positifs tout en conservant son gain en puissance.
Peut-être l'estimation du paramètre $\sigma^2$ se fait mieux en augmentant le nombre de bras.

log1BOP et log2BOP ont l'air de conserver leur comportement de défavoriser la dernière dose.
On remarque aussi que même si cela diminue le risque de faux positifs pour le bras 1 mais qui est en fait plus extrême qu'à 3 bras, cela augmente le risque de faux positifs dans le bras 2 (qui est comparable au bras 1 avec 3 doses).


### Scénario I2

La dernière dose est toxique peu importe le scénario.

Ci-dessous les résultats dans chaque bras, avec les partages d'information pour efficacité et toxicité :

```{r, fig.cap = "Proportion de conclusion à un traitement prometteur dans chaque bras pour le scénario I2 selon le nombre de bras"}
CaracBrasSensiBras %>%
  filter(cible %in% c("efftox", "both"), scenar == "ScI2") %>%
  ggplot(aes(ttt, rejet_h0, group = n_bras, color = n_bras)) +
  geom_point(size = 2) +
  geom_line() +
  facet_wrap(vars(methode)) +
  labs(x = "Dose", y = "Proportion de conclusion à un traitement prometteur", color = "# bras") +
  scale_color_discrete(type = c("black", "darkblue", "darkred")) +
  expand_limits(y = 0) +
  scale_y_continuous(labels = scales::percent_format())
```

Simon+Iva est moins puissant dans ce scénario que mBOP et a encore un taux de faux positifs plus important que mBOP à cause du caractère moins conservateur du monitoring de la toxicité.

On remarque la similitude entre mBOP et cbhmBOP comme pour les scénarios avec 3 bras.

powBOP est très élevé dans chaque bras, avec donc un risque majeur de faux positifs, encore plus élevé avec plus de bras.

hBOP garde une augmentation du risque de faux positifs dans les bras toxiques dans ce scénario.

log1BOP et log2BOP ont des résultats similaires entre les nombres de bras, avec augmentation de la puissance et petite augmentation du risque de faux positifs.


## Nombre moyen de patients

```{r, fig.width = 10, fig.height = 16, fig.cap = "Nombre moyen de patients dans chaque dose selon le nombre de bras"}
CaracBrasSensiBras %>%
  filter(cible %in% c("efftox", "both")) %>% 
  mutate(scenar = factor(scenar)) %>%
  ggplot(aes(x = tot_pat, y = methode, fill = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 4.5, ymax = 5.5, fill = "darkgrey", alpha = .6) +
  geom_col(position = position_dodge(width = 1)) +
  facet_grid(scenar ~ n_bras) +
  labs(x = "Nb moyen de patients", y = NULL)
```

Ici, je n'ai pas relevé de tendance différente entre 4/5 bras vs 3 bras.

## Estimation de l'efficacité


```{r}
CaracEssaisSensiBrasSup <- CaracEssaisSensiBras %>%
  filter(cible != "tox") %>% 
  left_join(TabScenarRegroup, by = c("scenar", "ttt", "n_bras" = "nb_bras"))
```


```{r, fig.width = 12, fig.height = 20}
CaracEssaisSensiBrasSup %>%
  group_by(scenar, ttt, methode, cible, n_bras) %>%
  summarise(biais_eff = mean(est_eff - eff_true), .groups = "drop") %>%
  ggplot(aes(biais_eff, methode, fill = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 4.5, ymax = 5.5, fill = "darkgrey", alpha = .6) +
  geom_hline(yintercept = seq(1.5, 6.5), linetype = "dashed", color = "darkgrey", linewidth = 1) +
  geom_col(position = position_dodge(width = 1)) +
  facet_grid(scenar ~ n_bras) +
  scale_x_continuous(labels = scales::percent_format()) +
  labs(x = "Biais absolu dans l'estimation de l'efficacité")
```

On retrouve les mêmes conclusions sur le biais, à savoir que le power prior est biaisé de façon imprévisible et log2BOP est biaisé fortement.
Et log1BOP est moins biaisé lorsque les OR sont proportionnels.


## Estimation de la toxicité


```{r, fig.width = 12, fig.height = 20}
CaracEssaisSensiBrasSup %>%
  group_by(scenar, ttt, methode, cible, n_bras) %>%
  summarise(biais_tox = mean(est_tox - tox_true), .groups = "drop") %>%
  ggplot(aes(biais_tox, methode, fill = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 4.5, ymax = 5.5, fill = "darkgrey", alpha = .6) +
  geom_hline(yintercept = seq(1.5, 6.5), linetype = "dashed", color = "darkgrey", linewidth = 1) +
  geom_col(position = position_dodge(width = 1)) +
  facet_grid(scenar ~ n_bras) +
  scale_x_continuous(labels = scales::percent_format()) +
  labs(x = "Biais absolu dans l'estimation de la toxicité", y = NULL)
```

Même constat que pour l'efficacité.


## Raison d'arrêt

```{r, fig.height = 30}
CaracBrasSensiBras %>% 
  mutate(arret_both = arret_fut + arret_tox - arret,
         arret_que_fut = arret_fut - arret_both,
         arret_que_tox = arret_tox - arret_both) %>% 
  select(methode, cible, scenar, ttt, n_bras, rejet_h0, arret_both, arret_que_fut, arret_que_tox) %>% 
  pivot_longer(6:9) %>% 
  filter(cible != "tox") %>% 
  mutate(name = factor(name, levels = c("rejet_h0", "arret_both", "arret_que_fut", "arret_que_tox"), labels = c("Prometteur", "Futile+Toxique", "Futile", "Toxique")),
         ordonnee = paste0(methode, " - ", ttt)) %>% 
  ggplot(aes(value, ordonnee, fill = name)) +
  # annotate("ribbon", x = c(-Inf, Inf), ymin = 4.5, ymax = 5.5, fill = "darkgrey", alpha = .6) +
  # geom_hline(yintercept = seq(1.5, 6.5), linetype = "dashed", color = "darkgrey", linewidth = 1) +
  geom_col() +
  facet_grid(scenar ~ n_bras) +
  scale_x_continuous(labels = scales::percent_format()) +
  scale_fill_discrete(type = c("darkgreen", "#5206ba", "#a7b025", "#cd1e05")) +
  labs(x = "% de raison d'arrêt", y = NULL)
```

Je n'ai pas vu non plus de changement par rapport à ce qui avait déjà été vu à 3 bras.


# Analyse de sensibilité : sensibilité aux priors

## hBOP

### Le modèle

Pour rappel, voici le modèle :

$$
\mu \sim N(m_1, s_1)\\
\sigma \sim N(0, s_2) [\sigma > 0]\\
logit(p_1,p_2,...,p_K) \sim N(\mu,\sigma)\\
(x_1,x_2,...,x_K)\sim Binom((n_1,n_2,...,n_K),(p_1,p_2,...,p_K))
$$

Voici un tableau résumant les différents priors explorés pour hBOP :

| Modèle       | $m_1$            | $s_1$        | $s_2$        |
| ------------ | ---------------- | ------------ | ------------ |
| hBOP         | logit($H_0$)     | 2.5          | 1            |
| H1_1         | **logit($H_1$)** | 2.5          | 1            |
| H1_2         | **logit(50%)**   | 2.5          | 1            |
| H2_1         | logit($H_0$)     | **ExNex**    | 1            |
| H2_2         | logit($H_0$)     | **10**       | 1            |
| H3_1         | logit($H_0$)     | 2.5          | **5**        |
| H3_2         | logit($H_0$)     | 2.5          | **0.5**      |

### Proportion de conclusion à un traitement prometteur

```{r, fig.cap = "Puissance globale dans le scénario 4 et FWER dans le scénario 2"}
CaracGlobalesPriors %>% 
  filter(grepl("^h|^H", methode), scenar %in% c("Sc2", "Sc4")) %>% 
  mutate(methode = ifelse(methode == "hBOP_1", "hBOP", methode)) %>% 
  ggplot(aes(x = rejet_glob, y = methode)) +
  geom_point(size = 2) +
  facet_wrap(vars(scenar), scales = "free_x") +
  expand_limits(x = 0) +
  scale_x_continuous(labels = scales:: percent_format()) +
  labs(y = NULL, x = "FWER/Puissance globale")
```

La puissance est écrasée par l'échelle, mais les variations sont au maximum de 0.08% entre les différents priors explorés.
En revanche, pour le FWER, on remarque que l'impact le plus grand est sur le prior de $\sigma$, le paramètre difficile à estimer dans le BHM.

```{r, fig.cap = "Proportion de conclusion à un traitement prometteur dans les différentes doses pour les 4 scénarios étudiés"}
CaracBrasPriors %>% 
  filter(grepl("^h|^H", methode)) %>% 
  mutate(methode = ifelse(methode == "hBOP_1", "hBOP", methode),
         ttt = gsub("^ttt", "D", ttt)) %>% 
  ggplot(aes(x = rejet_h0, y = methode, color = ttt, shape = ttt)) +
  geom_point(size = 2) +
  facet_wrap(vars(scenar), scales = "free_x") +
  expand_limits(x = 0) +
  scale_x_continuous(labels = scales:: percent_format()) +
  labs(y = NULL, x = "Proportion de conclusion à un traitement prometteur")
```

En comparant les résultats pour H1_1, H1_2, H2_1 et H2_2, on voit que les priors mis sur la moyenne de l'hyperpriors ont peu d'influence sur les résultats.
hBOP est donc robuste (relativement, car je n'ai pas non plus été mettre des priors très informatifs) à ces priors.

Par contre, avec H3_1 et H3_2, pour lesquels j'ai fait varier le prior sur le paramètre de variance du BHM, on voit que cela impacte les résultats.
Sur le scénario 4 et les bras prometteurs des scénarios I1 et I2, l'impact est limité, sûrement car il y a peu de liberté sur la variation.
Par contre, dans le bras 1 du scénario I1, et le bras 3 du scénario I2, on voit que le prior plus élevé pour la variance est plus conservateur et le prior plus faible est moins conservateur.
Dans le scénario 2, par contre, ça a l'air d'être en sens inverse.

En conclusion, le BHM est sensible au prior sur l'hyperparamètre de variance.

```{r, fig.width = 10, fig.height = 10, fig.cap = "Estimation de l'efficacité par les différents modèles dans les bras (ligne rouge = efficacité simulée)"}
Scenarios <- list(
  "Sc2"  = list(ttt1 = c(0.13, 0.12, 0.27, 0.48), ttt2 = c(0.15, 0.13, 0.27, 0.45), ttt3 = c(0.16, 0.14, 0.29, 0.41)),
  "Sc4"  = list(ttt1 = c(0.15, 0.35, 0.10, 0.40), ttt2 = c(0.17, 0.35, 0.11, 0.37), ttt3 = c(0.19, 0.36, 0.11, 0.34)),
  "ScI1" = list(ttt1 = c(0.10, 0.20, 0.15, 0.55), ttt2 = c(0.20, 0.30, 0.10, 0.40), ttt3 = c(0.19, 0.36, 0.11, 0.34)),
  "ScI2" = list(ttt1 = c(0.15, 0.35, 0.10, 0.40), ttt2 = c(0.18, 0.34, 0.12, 0.36), ttt3 = c(0.25, 0.30, 0.15, 0.30))
)
TabScenars <- do.call("rbind", lapply(names(Scenarios), \(nom_scenar) {
  do.call("rbind", lapply(names(Scenarios[[nom_scenar]]), \(nom_bras) {
    VecProba <- Scenarios[[nom_scenar]][[nom_bras]]
    data.frame("scenar" = nom_scenar, "ttt" = nom_bras, "eff_true" = VecProba[1] + VecProba[2], "tox_true" = VecProba[1] + VecProba[3]) %>% 
      mutate(ttt = gsub("^ttt", "D", ttt))
  }))
}))
CaracEssaisPriors %>% 
  filter(grepl("^h|^H", methode)) %>% 
  mutate(methode = ifelse(methode == "hBOP_1", "hBOP", methode),
         ttt = gsub("^ttt", "D", ttt)) %>% 
  ggplot(aes(y = est_eff, x = methode)) +
  geom_boxplot() +
  geom_hline(data = TabScenars, aes(yintercept = eff_true), color = "red", linetype = "dashed", linewidth = 1.2) +
  facet_grid(scenar ~ ttt) +
  labs(x = NULL, y = "Efficacité")
```

```{r, fig.width = 10, fig.height = 10, fig.cap = "Estimation de la toxicité par les différents modèles dans les bras (ligne rouge = toxicité simulée)"}
CaracEssaisPriors %>% 
  filter(grepl("^h|^H", methode)) %>% 
  mutate(methode = ifelse(methode == "hBOP_1", "hBOP", methode),
         ttt = gsub("^ttt", "D", ttt)) %>% 
  ggplot(aes(y = est_tox, x = methode)) +
  geom_boxplot() +
  geom_hline(data = TabScenars, aes(yintercept = tox_true), color = "red", linetype = "dashed", linewidth = 1.2) +
  facet_grid(scenar ~ ttt) +
  labs(x = NULL, y = "Toxicité")
```

Au niveau des estimations de l'efficacité et de la toxicité, pour la variation entre hBOP, H3_1 et H3_2, on a l'impression de voir une différence d'estimation d'efficacité dans le scénario I1 dose 1.
Et pour la toxicité, on voit une différence dans la dose 3 du scénario I2.
Et H3_2 a l'air d'avoir une dispersion un peu moins large, ce qui coinciderait avec le fait que ce soit un prior un peu moins fort pour la variance, mais qui est beaucoup moins prononcé que ce que je m'attendais à avoir.


## cbhmBOP

### Le modèle

Pour rappel, voici le modèle :

$$
\mu \sim N(m_1, s_1)\\
\sigma^2 = e^{a+b\times\log(\text{Mesure d'hétérogénéité})}\\
logit(p_1,p_2,...,p_K) \sim N(\mu,\sigma)\\
(x_1,x_2,...,x_K)\sim Binom((n_1,n_2,...,n_K),(p_1,p_2,...,p_K))
$$

Voici un tableau résumant les différents priors explorés pour hBOP :

| Modèle       | $m_1$            | $s_1$        | 
| ------------ | ---------------- | ------------ | 
| cbhmBOP      | logit($H_0$)     | 2.5          | 
| C1_1         | **logit($H_1$)** | 2.5          | 
| C1_2         | **logit(50%)**   | 2.5          | 
| C2_1         | logit($H_0$)     | **ExNex**    | 
| C2_2         | logit($H_0$)     | **10**       | 

### Proportion de conclusion à un traitement prometteur

```{r, fig.cap = "Puissance globale dans le scénario 4 et FWER dans le scénario 2"}
CaracGlobalesPriors %>% 
  filter(grepl("^c|^C", methode), scenar %in% c("Sc2", "Sc4")) %>% 
  mutate(methode = ifelse(methode == "cbhmBOP_1", "cbhmBOP", methode)) %>% 
  ggplot(aes(x = rejet_glob, y = methode)) +
  geom_point(size = 2) +
  facet_wrap(vars(scenar), scales = "free_x") +
  expand_limits(x = 0) +
  scale_x_continuous(labels = scales:: percent_format()) +
  labs(y = NULL, x = "FWER/Puissance globale")
```

La puissance est écrasée par l'échelle, mais les variations sont au maximum de 0.06% entre les différents priors explorés.
Pour le FWER, on a aussi de faibles variation entre les différents priors.

```{r, fig.cap = "Proportion de conclusion à un traitement prometteur dans les différentes doses pour les 4 scénarios étudiés"}
CaracBrasPriors %>% 
  filter(grepl("^c|^C", methode)) %>% 
  mutate(methode = ifelse(methode == "cbhmBOP_1", "cbhmBOP", methode),
         ttt = gsub("^ttt", "D", ttt)) %>% 
  ggplot(aes(x = rejet_h0, y = methode, color = ttt, shape = ttt)) +
  geom_point(size = 2) +
  facet_wrap(vars(scenar), scales = "free_x") +
  expand_limits(x = 0) +
  scale_x_continuous(labels = scales:: percent_format()) +
  labs(y = NULL, x = "Proportion de conclusion à un traitement prometteur")
```

Cela confirme ce qui était montré sur le FWER et la puissance globale, le cbhmBOP est robuste à des variation des priors.
Au moins tant qu'on ne prend pas des priors avec une variance trop faible (testé jusque environ 1.8 pour les priors type ExNex).


## log1BOP

### Le modèle

Pour rappel, voici le modèle :

$$
\alpha\sim N(m_1,s_1)\\
\beta\sim N(m_2,s_2)\\
y\sim \text{Bernoulli}(expit(\alpha+\beta\times\text{Dose}))
$$

Voici un tableau résumant les différents priors explorés pour hBOP :

| Modèle       | $m_1$            | $s_1$        | $e^{m_2}$    | $s_2$        |
| ------------ | ---------------- | ------------ | ------------ | ------------ |
| log1BOP      | logit($H_0$)     | 2.5          | 1.52/1.25    | 2.5          |
| L1_1         | **logit($H_1$)** | 2.5          | 1.52/1.25    | 2.5          |
| L1_2         | **logit(50%)**   | 2.5          | 1.52/1.25    | 2.5          |
| L2_1         | logit($H_0$)     | **1**        | 1.52/1.25    | 2.5          |
| L2_2         | logit($H_0$)     | **10**       | 1.52/1.25    | 2.5          |
| L3_1         | logit($H_0$)     | 2.5          | 1.52/1.25    | **1**        |
| L3_2         | logit($H_0$)     | 2.5          | 1.52/1.25    | **10**       |
| L4_1         | logit($H_0$)     | 2.5          | **1/1**      | 2.5          |
| L4_2         | logit($H_0$)     | 2.5          | **2.7/2.7**  | 2.5          |
| L5_1         | logit($H_0$)     | 2.5          | **1/1**      | **1**        |
| L5_2         | logit($H_0$)     | 2.5          | **2.7/2.7**  | **1**        |

### Proportion de conclusion à un traitement prometteur

```{r, fig.cap = "Puissance globale dans le scénario 4 et FWER dans le scénario 2"}
CaracGlobalesPriors %>% 
  filter(grepl("^l|^L", methode), scenar %in% c("Sc2", "Sc4")) %>% 
  mutate(methode = ifelse(methode == "log1BOP_1", "log1BOP", methode)) %>% 
  ggplot(aes(x = rejet_glob, y = methode)) +
  geom_point(size = 2) +
  facet_wrap(vars(scenar), scales = "free_x") +
  expand_limits(x = 0) +
  scale_x_continuous(labels = scales:: percent_format()) +
  labs(y = NULL, x = "FWER/Puissance globale")
```

La puissance est écrasée par l'échelle, mais les variations sont au maximum de 0.04% entre les différents priors explorés.
En revanche, pour le FWER, on remarque que l'impact le plus grand est de donner un prior plus informatif sur la variance de l'intercept.

```{r, fig.cap = "Proportion de conclusion à un traitement prometteur dans les différentes doses pour les 4 scénarios étudiés"}
CaracBrasPriors %>% 
  filter(grepl("^l|^L", methode)) %>% 
  mutate(methode = ifelse(methode == "log1BOP_1", "log1BOP", methode),
         ttt = gsub("^ttt", "D", ttt)) %>% 
  ggplot(aes(x = rejet_h0, y = methode, color = ttt, shape = ttt)) +
  geom_point(size = 2) +
  facet_wrap(vars(scenar), scales = "free_x") +
  expand_limits(x = 0) +
  scale_x_continuous(labels = scales:: percent_format()) +
  labs(y = NULL, x = "Proportion de conclusion à un traitement prometteur")
```

En comparant les résultats pour L1_1, L1_2, L3_1, L3_2, L4_1 et L4_1, on voit que les priors changé ont un impact limité sur les propriétés du schéma.
L5_2 fait aussi environ pareil que log1BOP, mais L5_1 apparaît avec une petite augmentation du taux de faux positifs qui n'est peut-être pas très importante, mais pourrait aller avec le fait qu'on donne un prior plus informatif avec une pente plate sur le $\beta$ de la régression logistique.
Cela fonne peut-être un prior plus informatif d'une relation plate et pour la dose 1, va considérer qu'elle est plus efficace que ce qu'elle est vraiment.

Ensuite, on a du changement entre L2_1 et L2_2 avec L2_1 qui a un plus grand taux de faux positifs.
Ici encore on a touché au prior de variance, mais cette fois-ci de l'intercept.
L2_1 a un prior plus informatif pour l'intercept, mais pourtant centré sur $H_0$.

Il faut donc à mon avis faire attention en donnant des priors informatifs en cas de régression logistique, raison pour laquelle je suis revenu à une variance de 2.5^2^ au lieu de 1.


```{r, fig.width = 10, fig.height = 10, fig.cap = "Estimation de l'efficacité par les différents modèles dans les bras (ligne rouge = efficacité simulée)"}
CaracEssaisPriors %>% 
  filter(grepl("^l|^L", methode)) %>% 
  mutate(methode = ifelse(methode == "log1BOP_1", "log1BOP", methode),
         ttt = gsub("^ttt", "D", ttt)) %>% 
  ggplot(aes(x = est_eff, y = methode)) +
  geom_boxplot() +
  geom_vline(data = TabScenars, aes(xintercept = eff_true), color = "red", linetype = "dashed", linewidth = 1.2) +
  facet_grid(scenar ~ ttt) +
  labs(x = NULL, y = "Efficacité")
```

```{r, fig.width = 10, fig.height = 10, fig.cap = "Estimation de la toxicité par les différents modèles dans les bras (ligne rouge = toxicité simulée)"}
CaracEssaisPriors %>% 
  filter(grepl("^l|^L", methode)) %>% 
  mutate(methode = ifelse(methode == "log1BOP_1", "log1BOP", methode),
         ttt = gsub("^ttt", "D", ttt)) %>% 
  ggplot(aes(x = est_tox, y = methode)) +
  geom_boxplot() +
  geom_vline(data = TabScenars, aes(xintercept = tox_true), color = "red", linetype = "dashed", linewidth = 1.2) +
  facet_grid(scenar ~ ttt) +
  labs(x = NULL, y = "Toxicité")
```

Au niveau des estimations de l'efficacité et de la toxicité, on retrouve le schéma L2_1 qui a une estimation légèrement différente des autres, mais sinon je n'ai pas l'impression de déceler de grandes différences.



# Résumé par méthode

## Simon+Iva

Les différences s'expliquent par les règles de décision.

Pour le schéma de Simon, il faut plus de réponses à l'étape 1 pour passer à l'étape 2, donc on a un schéma plus conservateur sur l'efficacité.

Par contre, pour le monitoring de la toxicité, à l'analyse finale, il faut plus de toxicités avec Ivanova pour conclure à la toxicité donc mBOP est plus conservateur sur la toxicité.

Pour autant, le schéma mBOP semble être plus puissant.

L'estimation donne plus de variabilité que mBOP.


## powBOP

Le partage d'information statique semble être une mauvaise idée car selon les scénarios, on partage l'information de bras potentiellement efficaces et non toxiques à des bras futile et/ou toxique.
On a pu voir que cela augmente fortement la puissance parfois mais que cela peut augmenter fortement le risque de faux positifs.

Au niveau de l'estimation, c'est assez imprévisible comme biais, ce qui est un autre point négatif.


## hBOP

Pour les scénarios 1 à 4, le modèle hiérarchique se débrouille bien avec un FWER diminué, et une meilleure puissance dans les bras.
Mais c'était le cas idéal pour un modèle BHM puisque tous les bras sont similaires.

Dans les autres scénarios, on a une augmentation du risque de faux positifs et une augmentation de la puissance.
On a globalement une plus grande proportion de conclusion à un traitement prometteur avec hBOP que pour mBOP.

Le recrutement de plus de patients en moyenne est fait pour ce schéma.

Le modèle hiérarchique est surtout sensible à son prior sur l'hyperparamètre de variance.


## cbhmBOP

Au niveau des scénarios pour les hypothèses, on a une légère augmentation du risque de faux positifs avec une légère augmentation de la puissance.

Globalement on a des résultats similaires au mBOP, mais avec peut-être un peu moins de patients.

cbhmBOP est peu sensible aux hyperpriors.


## Modèles logistiques

bop_log2, lorsqu'on ne partage l'information que sur la toxicité, est très conservateur dans le bras 3 et moins dans le bras 1 pour l'hypothèse nulle globale.
En ajoutant l'information d'efficacité, cela inverse la tendance.
bop_log1 a une légère augmentation du FWER, mais pas d'augmentation du risque de faux positif dans les bras.

Concernant les scénarios tout H1, on a un plus grand gain de puissance pour bop_log2.
A noter que pour bop_log2, on a gain de puissance dans une dose extrême et perte de puissance dans l'autre extrême alors que pour bop_log1, le gain est surtout dans la dose intermédiaire, mais pas de perte de puissance dans l'un des bras.

Dans les scénarios faciles, on retrouve une petite augmentation du risque de faux positifs, mais avec gain de puissance comparable pour les 2 (et perte de puissance pour bop_log2 dans le bras 3).

Dans les scénarios intermédiaires, bop_log2 contrôle mieux le risque de faux positifs chez la dose 3.
Dans le cas de probabilités intermédiaires, on conserve quand-même une grande proportion de conclusion à un traitement prometteur.

Pour log2BOP, l'estimation est très biaisée du fait de la forme croissante de la relation, et log1BOP est plus biaisé lorsque les OR ne sont pas proportionnels.

On a une économie de patients pour les scénarios toxiques.

Par ailleurs, ce schéma augmente encore plus les faux positifs en augmentant le nombre de bras de traitement.

Donner des priors trop informatifs peut entraîner un risque accru de faux positifs.


# Variation de la régression logistique bayésienne

En fait, j'ai mal lu Neuenschwander, et il proposait d'utiliser $log(\frac{d}{d^*})$ alors que j'ai pris $\frac{d}{d^*}$.
En pratique, je pense que cela va peu changer car on va passer de 1/2/3 à 0/0.69/1.10.

J'ai refait tourner les scénarios pour pouvoir comparer les résultats.

**FWER et puissance (partage pour efficacité et toxicité) :**

```{r}
CaracGlobalesLogit %>% 
  filter(cible == "efftox", scenar %in% paste0("Sc", 1:4)) %>% 
  select(methode, scenar, rejet_glob) %>% 
  mutate(rejet_glob = sprintf("%.2f%%", 100 * rejet_glob),
         scenar = paste0(scenar, ifelse(scenar %in% c("Sc1", "Sc2"), " (FWER)", " (Puissance)"))) %>% 
  pivot_wider(names_from = scenar, values_from = rejet_glob) %>% 
  mutate(methode = factor(methode, levels = c("log1BOP", "verlog1BOP", "log2BOP", "verlog2BOP"))) %>% 
  arrange(methode) %>% 
  flextable() %>% 
  theme_box() %>% 
  autofit()
```

On voit donc des résultats très proches sur le FWER et la puissance dans les 4 scénarios étudiés.

```{r, fig.cap = "Proportion de conclusion à un traitement efficace et non toxique dans les scénarios 1 à 4"}
Graphes <- CaracBrasLogit %>% 
  filter(cible %in% c("efftox", "both"), scenar %in% c("Sc1", "Sc2", "Sc3", "Sc4")) %>% 
  mutate(ttt = gsub("ttt", "D", ttt),
         scenar = factor(scenar, levels = c("Sc1", "Sc2", "Sc3", "Sc4")),
         methode = factor(methode, levels = rev(c("log1BOP", "verlog1BOP", "log2BOP", "verlog2BOP")))) %>% 
  split(.$scenar) %>% 
  map(\(Sc) {
    if (Sc$scenar[1] %in% c("Sc1", "Sc2")) {
      LimiteSup <- .05
    } else {
      LimiteSup <- 1
    }
    ggplot(Sc, aes(rejet_h0, methode, color = ttt, shape = ttt)) +
      geom_point(position = position_dodge2(width = .2), size = 4) +
      facet_wrap(vars(scenar), scales = "free_x") +
      coord_cartesian(xlim = c(0, LimiteSup)) +
      scale_x_continuous(labels = scales::percent_format()) +
      scale_color_discrete(type = c("darkred", "steelblue", "orange")) +
      labs(y = NULL, x = "Proportion of conclusion to promising dose", color = "Dose", shape = "Dose") +
      theme_light(base_size = 15) +
      theme(strip.background = element_rect(fill = "white", color = "black", size = 1.6),
            strip.text = element_text(face = "bold", color = "black"))
  })
wrap_plots(Graphes, guides = "collect", axes = "collect_y", axis_titles = "collect")
```

Au niveau des caractéristiques dans les différents bras, on a des résultats très proches, mais avec quelques différences sur les bras extrêmes : dose 1 et 3.

```{r, fig.cap = "Proportion de conclusion à un traitement efficace et non toxique dans les scénarios 5 à 8"}
Graphes <- CaracBrasLogit %>% 
  filter(cible %in% c("efftox", "both"), scenar %in% c("Sc5", "Sc6", "Sc7", "Sc8")) %>% 
  mutate(ttt = gsub("ttt", "D", ttt),
         scenar = factor(scenar, levels = c("Sc5", "Sc6", "Sc7", "Sc8")),
         methode = factor(methode, levels = rev(c("log1BOP", "verlog1BOP", "log2BOP", "verlog2BOP")))) %>% 
  split(.$scenar) %>% 
  map(\(Sc) {
    if (Sc$scenar[1] %in% c("Sc1", "Sc2")) {
      LimiteSup <- .05
    } else {
      LimiteSup <- 1
    }
    ggplot(Sc, aes(rejet_h0, methode, color = ttt, shape = ttt)) +
      geom_point(position = position_dodge2(width = .2), size = 4) +
      facet_wrap(vars(scenar), scales = "free_x") +
      coord_cartesian(xlim = c(0, LimiteSup)) +
      scale_x_continuous(labels = scales::percent_format()) +
      scale_color_discrete(type = c("darkred", "steelblue", "orange")) +
      labs(y = NULL, x = "Proportion of conclusion to promising dose", color = "Dose", shape = "Dose") +
      theme_light(base_size = 15) +
      theme(strip.background = element_rect(fill = "white", color = "black", size = 1.6),
            strip.text = element_text(face = "bold", color = "black"))
  })
wrap_plots(Graphes, guides = "collect", axes = "collect_y", axis_titles = "collect")
```

Dans le scénario 5 où la 1^ère^ dose est futile et la 3^ème^ est toxique, la nouvelle régression logistique augmente un peu le risque de faux positif pour la dose 3 et le diminue un peu pour la dose 1.
Par contre, on diminue la proportion de vrai positifs dans la dose 2.
Le scénario 6 montre les mêmes résultats que le scénario 5.

Dans le scénario 7, on retrouve l'augmentation des faux positifs avec la regression logistique sur le log dans la dose 3, et la diminution de la proportion de conclustion à une dose prometteuse dans la dose 2.

Le scénario 8 ne comporte aucune dose prometteuse. 
On retrouve le même comportement : augmentation de la proportion de conclusion à une dose prometteuse pour la dose 3, et diminution pour les doses 1 et 2.

```{r, fig.cap = "Proportion de conclusion à un traitement efficace et non toxique dans les scénarios I1 et I2"}
Graphes <- CaracBrasLogit %>% 
  filter(cible %in% c("efftox", "both"), scenar %in% c("ScI1", "ScI2")) %>% 
  mutate(ttt = gsub("ttt", "D", ttt),
         scenar = factor(scenar, levels = c("ScI1", "ScI2")),
         methode = factor(methode, levels = rev(c("log1BOP", "verlog1BOP", "log2BOP", "verlog2BOP")))) %>% 
  split(.$scenar) %>% 
  map(\(Sc) {
    if (Sc$scenar[1] %in% c("Sc1", "Sc2")) {
      LimiteSup <- .05
    } else {
      LimiteSup <- 1
    }
    ggplot(Sc, aes(rejet_h0, methode, color = ttt, shape = ttt)) +
      geom_point(position = position_dodge2(width = .2), size = 4) +
      facet_wrap(vars(scenar), scales = "free_x") +
      coord_cartesian(xlim = c(0, LimiteSup)) +
      scale_x_continuous(labels = scales::percent_format()) +
      scale_color_discrete(type = c("darkred", "steelblue", "orange")) +
      labs(y = NULL, x = "Proportion of conclusion to promising dose", color = "Dose", shape = "Dose") +
      theme_light(base_size = 15) +
      theme(strip.background = element_rect(fill = "white", color = "black", size = 1.6),
            strip.text = element_text(face = "bold", color = "black"))
  })
wrap_plots(Graphes, guides = "collect", axes = "collect_y", axis_titles = "collect")
```

Globalement on retrouve cette fois encore le même comportement.
La modification de mettre $log\frac{d}{d^*}$ a l'air donc de profiter aux scénarios avec un dose futile.

On peut regarder dans ces 2 scénarios en plus, le pourcentage de sélection correcte et les estimations d'efficacité et de toxicité.

**Pourcentage de sélection correcte (doses 2 et 3 pour scénario I1 et 1 et 2 pour scénario I2) dans les scénarios de l'Ibrutinib**

```{r}
CaracEssaisLogit %>% 
  filter(cible != "tox", scenar %in% c("ScI1", "ScI2")) %>% 
  group_by(scenar, methode, n_simu) %>% 
  summarise(choix = ifelse(all(decision != "Accept the treatment"), "", paste(ttt[decision == "Accept the treatment"], collapse = "-")), .groups = "drop") %>% 
  mutate(verite = ifelse(scenar == "ScI1", "ttt2-ttt3", "ttt1-ttt2"),
         final = as.numeric(verite == choix)) %>% 
  count(scenar, methode, final) %>% 
  mutate(pct = sprintf("%.1f%%", 100 * n / sum(n)), .by = c(scenar, methode)) %>% 
  filter(final == 1) %>% 
  complete(scenar, methode, fill = list(pct = "0.0%%")) %>% 
  select(methode, scenar, pct) %>% 
  pivot_wider(names_from = "scenar", values_from = "pct") %>% 
  mutate(methode = factor(methode, levels = c("log1BOP", "verlog1BOP", "log2BOP", "verlog2BOP"))) %>% 
  arrange(methode) %>% 
  flextable() %>% 
  theme_box() %>% 
  autofit()
```

On retombe sur l'intuition qu'on avait avec la figure sur les proportions de conclusion à une dose prometteuse : la modification ("ver...") est bénéfique dans le cas où on est dans un problème de futilité.

```{r, fig.height = 10}
ListeScenars <- list(
  Sc1  = list(ttt1 = c(0.15, 0.15, 0.25, 0.45), ttt2 = c(0.15, 0.15, 0.25, 0.45), ttt3 = c(0.15, 0.15, 0.25, 0.45)),
  Sc2  = list(ttt1 = c(0.13, 0.12, 0.27, 0.48), ttt2 = c(0.15, 0.13, 0.27, 0.45), ttt3 = c(0.16, 0.14, 0.29, 0.41)),
  Sc3  = list(ttt1 = c(0.20, 0.30, 0.10, 0.40), ttt2 = c(0.20, 0.30, 0.10, 0.40), ttt3 = c(0.20, 0.30, 0.10, 0.40)),
  Sc4  = list(ttt1 = c(0.15, 0.35, 0.10, 0.40), ttt2 = c(0.17, 0.35, 0.11, 0.37), ttt3 = c(0.19, 0.36, 0.11, 0.34)),
  Sc5  = list(ttt1 = c(0.11, 0.19, 0.17, 0.53), ttt2 = c(0.20, 0.30, 0.10, 0.40), ttt3 = c(0.25, 0.30, 0.15, 0.30)),
  Sc6  = list(ttt1 = c(0.14, 0.26, 0.14, 0.46), ttt2 = c(0.20, 0.30, 0.10, 0.40), ttt3 = c(0.25, 0.30, 0.15, 0.30)),
  Sc7  = list(ttt1 = c(0.18, 0.32, 0.12, 0.38), ttt2 = c(0.22, 0.28, 0.15, 0.35), ttt3 = c(0.23, 0.27, 0.17, 0.33)),
  Sc8  = list(ttt1 = c(0.12, 0.18, 0.18, 0.52), ttt2 = c(0.17, 0.23, 0.18, 0.42), ttt3 = c(0.23, 0.27, 0.17, 0.33)),
  ScI1 = list(ttt1 = c(0.10, 0.20, 0.15, 0.55), ttt2 = c(0.20, 0.30, 0.10, 0.40), ttt3 = c(0.19, 0.36, 0.11, 0.34)),
  ScI2 = list(ttt1 = c(0.15, 0.35, 0.10, 0.40), ttt2 = c(0.18, 0.34, 0.12, 0.36), ttt3 = c(0.25, 0.30, 0.15, 0.30))
)
NomsScenars <- c(
  "Sc1"  = "Sc1 : Global Null",
  "Sc2"  = "Sc2 : Global Null increasing",
  "Sc3"  = "Sc3 : Global Alternative",
  "Sc4"  = "Sc4 : Global Alternative increasing",
  "ScI1" = "ScI1 : 1st dosis futile",
  "ScI2" = "ScI2 : 3rd dosis toxic",
  "Sc5"  = "Sc5 : 1st dosis futile and 3rd dosis toxic",
  "Sc6"  = "Sc6 : 3rd dosis toxic and 1st dosis intermediate",
  "Sc7"  = "Sc7 : 2nd dosis intermediate and 3rd dosis toxic",
  "Sc8"  = "Sc8 : No promising dosis"
)
TabScenars <- do.call("rbind", lapply(names(ListeScenars), \(nom_scenar) {
  do.call("rbind", lapply(names(ListeScenars[[nom_scenar]]), \(nom_bras) {
    VecProba <- ListeScenars[[nom_scenar]][[nom_bras]]
    data.frame("scenar" = nom_scenar, "ttt" = nom_bras, "eff_true" = VecProba[1] + VecProba[2], "tox_true" = VecProba[1] + VecProba[3]) %>% 
      mutate(ttt = gsub("^ttt", "D", ttt))
  }))
}))
Graphe <- ((CaracEssaisLogit %>% 
              filter(cible != "tox", scenar %in% c("ScI1", "ScI2")) %>% 
              mutate(ttt = gsub("^ttt", "D", ttt),
                     methode = factor(methode, levels = c("log1BOP", "verlog1BOP", "log2BOP", "verlog2BOP"))) %>% 
              ggplot(aes(y = est_eff, x = methode, fill = methode)) +
              geom_boxplot(alpha = .6) +
              geom_hline(data = TabScenars %>% filter(scenar %in% c("ScI1", "ScI2")), aes(yintercept = eff_true), 
                         color = "darkred", linetype = "solid", linewidth = .7) +
              facet_grid(scenar ~ ttt) +
              scale_fill_discrete(type = c("#0f3d9b", "#08a448", "#7846ab", "#c33215", "#dd790e", "#11caa6", "#07772e")) + 
              theme_light(base_size = 13) +
              scale_y_continuous(labels = scales::percent_format()) +
              theme(legend.position = "none",
                    strip.background = element_rect(fill = "white", color = "black", size = 1.2),
                    strip.text = element_text(face = "bold", color = "black", size = 12),
                    axis.text.x = element_markdown(angle = 45, hjust = 1)) +
              labs(x = NULL, y = "Efficacy")) /
             (CaracEssaisLogit %>% 
                filter(cible != "tox", scenar %in% c("ScI1", "ScI2")) %>% 
                mutate(ttt = gsub("^ttt", "D", ttt),
                       methode = factor(methode, levels = c("log1BOP", "verlog1BOP", "log2BOP", "verlog2BOP"))) %>% 
                ggplot(aes(y = est_tox, x = methode, fill = methode)) +
                geom_boxplot(alpha = .6) +
                geom_hline(data = TabScenars %>% filter(scenar %in% c("ScI1", "ScI2")), aes(yintercept = tox_true), 
                           color = "darkred", linetype = "solid", linewidth = .7) +
                facet_grid(scenar ~ ttt) +
                scale_fill_discrete(type = c("#0f3d9b", "#08a448", "#7846ab", "#c33215", "#dd790e", "#11caa6", "#07772e")) + 
                theme_light(base_size = 13) +
                scale_y_continuous(labels = scales::percent_format()) +
                theme(legend.position = "none",
                      strip.background = element_rect(fill = "white", color = "black", size = 1.2),
                      strip.text = element_text(face = "bold", color = "black", size = 12),
                      axis.text.x = element_markdown(angle = 45, hjust = 1)) +
                labs(x = NULL, y = "Toxicity"))) +
  plot_annotation(tag_levels = "A")
plot(Graphe)
```

Au niveau des estimations de l'efficacité, globalement la modification pour le log a l'air de s'en sortir mieux.

Pour la toxicité, cela semble être l'inverse.







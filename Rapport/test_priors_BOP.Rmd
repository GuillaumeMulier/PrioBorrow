---
title: "Tentative de borrow avec le BOP2"
author: "Guillaume Mulier, Lucie Biard, Vincent Levy"
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: yes
    theme: sandstone
    number_sections: yes
    code_folding: hide
    toc_float: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.width = 11,
                      fig.height = 8)
```

```{r pkg-import, include = FALSE}
library(tidyverse)
here::i_am("Rapport/test_priors_BOP.Rmd")
library(here)
library(knitr)
library(rlang)
library(flextable)
library(readxl)

theme_set(theme_light(base_size = 14) +
            theme(strip.background = element_rect(fill = "white", color = "black", size = 1.2),
                  strip.text = element_text(face = "bold", color = "black")))
```

```{r data-processing}
CaracGlobales <- list()
CaracBras <- list()
CaracEssais <- list()

walk(1:11, \(fich_num) {
  Fichiers <- paste0("Data/resultats_priors_20241007_", 1:11, ".RData")
  fichier_temp <- Fichiers[fich_num]
  load(here(fichier_temp), envir = current_env())
  assign("CaracGlobales", append(CaracGlobales, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[1]]))))), global_env())
  assign("CaracBras", append(CaracBras, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[2]]))))), global_env())
  assign("CaracEssais", append(CaracEssais, list(do.call("rbind", lapply(ResT, \(x) cbind(x[[3]], x[[4]]))))), global_env())
})
CaracGlobales <- do.call("rbind", CaracGlobales)
CaracGlobales$methode[CaracGlobales$methode == "mBOP"] <- "mBOP_both"
CaracGlobales$methode <- gsub("bop_log", "boplog", CaracGlobales$methode)
CaracGlobales <- separate(CaracGlobales, methode, c("methode", "cible"), "_")
CaracBras <- do.call("rbind", CaracBras)
CaracBras$methode <- gsub("bop_log", "boplog", CaracBras$methode)
CaracBras$methode[CaracBras$methode == "mBOP"] <- "mBOP_both"
CaracBras <- separate(CaracBras, methode, c("methode", "cible"), "_")
CaracEssais <- do.call("rbind", CaracEssais)
CaracEssais$methode[CaracEssais$methode == "mBOP"] <- "mBOP_both"
CaracEssais$methode <- gsub("bop_log", "boplog", CaracEssais$methode)
CaracEssais <- separate(CaracEssais, methode, c("methode", "cible"), "_")
CaracEssais$larg_ic_eff <- CaracEssais$icsup_eff - CaracEssais$icinf_eff
CaracEssais$larg_ic_tox <- CaracEssais$icsup_tox - CaracEssais$icinf_tox
```


```{css, echo = FALSE}
.caption {
  font-weight: bold;
  font-size: medium;
}
```


# Petite recherche biblio

J'ai voulu regarder ce qui se faisait dans les essais dose-ranging randomisés.
Pour cela, j'ai fait une petite recherche biblio en prenant les essais randomisés avec plusieurs doses d'un même médicament.
Je n'ai pas restreint à l'oncologie, mais en ajoutant "AND (oncology OR cancerology)" on obtient 87 résultats sans restreindre sur l'année (et environ 150 en retirant le critère sur les phases).

Equation de recherche : ("dose ranging") AND (clinical trial) AND (phase 2 OR phase II) + restriction de l'année entre 2020 et 2024.
180 résultats trouvés au total.

```{r}
TabBib <- suppressMessages(read_xlsx(here("Data/biblio_doserangin.xlsx"))) %>% 
  select(1:8) %>% 
  mutate(modele_utilise = ifelse(grepl("\\(", Method), gsub("^.*\\((.*)\\)$", "\\1", Method), NA_character_),
         Method = gsub(" \\(.*\\)", "", Method),
         nb_pat_ttt = round(Nb_pat / N_bras))
```

:::: {style="display: flex;"}

::: {}

```{r, fig.cap = "Répartition des essais trouvés selon l'année de publication de l'article"}
ggplot(TabBib, aes(x = Annee)) +
  geom_bar()+
  labs(x = "Année", y = "Effectif")
```

:::

::: {}

```{r, fig.cap = "Répartition des essais trouvés selon leur phase"}
ggplot(TabBib, aes(x = Phase)) +
  geom_bar()+
  labs(y = "Effectif")
```

Assez bizarrement, même si dans l'équation de recherche j'ai demandé phase II, on a quelques phase I et III.
J'ai exclus les articles pour lesquels l'essai ne randomisait pas plusieurs doses d'un même médicament.

:::

::::

:::: {style="display: flex;"}

::: {}

```{r, fig.cap = "Nombre de bras dans les essais"}
ggplot(TabBib, aes(x = N_bras)) +
  geom_bar()+
  labs(x = "Nombre de bras", y = "Effectif")
```

:::

::: {}

```{r, fig.cap = "Méthode d'analyse utilisée"}
ggplot(TabBib, aes(y = Method)) +
  geom_bar() +
  labs(x = "Effectif")
```

A noter que dans test avec/sans correction, j'ai aussi inclus des estimations dès lors qu'il y avait un intervalle de confiance.

:::

::::

:::: {style="display: flex;"}

::: {}

```{r, fig.cap = "Nombre de patients par essai"}
ggplot(TabBib, aes(x = factor(N_bras), y = Nb_pat)) +
  geom_boxplot() +
  labs(x = "Nombre de bras", y = "Nombre de patients")
```

:::

::: {}

```{r, fig.cap = "Nombre moyen de patients par bras par essai"}
ggplot(TabBib, aes(x = factor(N_bras), y = nb_pat_ttt)) +
  geom_boxplot() +
  labs(x = "Nombre de bras", y = "Nombre moyen de patients par bras")
```


:::

::::

Il semble y avoir autour de 50 patients par bras, ce qui est proche des 45 qu'on a pris pour les simulations.
Aussi, la méthode d'analyse la plus répandue est de tester dans chaque bras sans corriger pour les tests multiples, suivi des tests avec correction et des modèles avec réponse selon la dose.
En mode, on a 3 bras. 
Sachant qu'il y a beaucoup d'essais contrôlés, on a bien 3 bras de traitements comme dans les simulations faites. 




# Les différents modèles

## BOP2 : "mBOP"

La 1^ère^ façon d'analyser est le BOP2 classique qu'on applique à un essai multi-bras : 

- stop pour futilité si $Pr(\pi_\text{eff}\leq\phi_\text{eff}|D_n)>C_n$
- stop pour toxicité si $Pr(\pi_\text{tox}>\phi_\text{tox}|D_n)>C_n$

avec $\phi_\text{eff}$ et $\phi_\text{tox}$ qui sont déterminés par les hypothèses prises par les cliniciens.

Les probabilités a posteriori sont calculées avec des lois beta conjuguées :

$$
Pr(\pi|D_n)=Beta(a_0+x,b_0+n-x)
$$

avec $a_0$ et $b_0$ les paramètres du prior, $x$ et $n$ les nombres d'évènements et de patients dans le bras d'intérêt.


## BOP2 avec power prior en partageant l'information selon test de Fisher : "tBOP a=... $s$=..."

En 2^ème^ choix, j'ai choisi de combiner le BOP2 avec le power prior d'Ibrahim et Chen avec un exposant qui est une constante.
Cela a été appliqué à la toxicité uniquement, ou à l'efficacité et la toxicité.

La probabilité a posteriori s'écrit de la façon suivante :

$$
Pr(\pi|D_n)=Beta(a_0+x+a\times x_p,b_0+n-x+a\times(n_p-x_p))
$$

avec $x_p$ et $n_p$ le nombre de toxicités et de patients dans les autres bras qui ne sont pas significativement différents du bras d'intérêt ; et $a$ l'exposant du power prior.

Et on ne partage l'information que si la différence entre la toxicité observée dans les groupes est acceptable (quantifiée par une p-value au-dessus d'un certain seuil $s$).
$x_p$ sera donc dans les bras qui ne sont pas différents significativement à un seuil $s$ près du bras qu'on est en train d'évaluer.


## BOP2 en partageant l'information des bras arrêtés en respectant une séquence : "seqBOP"

Cette fois, j'ai décidé de garder l'ordre des doses et de le prendre en compte dans les règles de décision.
L'idée était que si une forte dose n'est pas efficace, il y a des chances pour que les doses du dessous soient futiles elles aussi. 
Et pour la toxicité, si une faible dose est toxique, il y a des chances pour que les doses du dessus aussi.
Donc j'ai partagé l'information complètement, mais en respectant cette règle : on partage l'information des bras à une dose inférieure et arrêtés pour toxicité.

NB : j'ai testé aussi la même chose mais en partageant aussi l'efficacité.
Dans ce cas, on partage l'information des bras à une dose supérieure mais qui sont futiles, avec l'idée que si une dose supérieure est futile, il y a des chances que celle du dessous aussi.


## BOP2 en utilisant un modèle hiérarchique pour la toxicité : "hBOP"

L'hypothèse derrière un modèle hiérarchique serait l'échangeabilité, ce qui est peu probable dans notre cas.
De ce que j'ai lu en faisant la biblio, souvent dans les basket trials, on utilise ce type de modèle en faisant l'hypothèse que l'efficacité d'un traitement sera la même dans toutes les indications par exemple.
Néanmoins, je pense que cela peut contribuer à diminuer la variance et donc avoir une meilleure précision autour de l'estimation de toxicité.

A noter que ce modèle est plus dur à estimer, et il y a des divergences en nombre variable selon les jeux de données.
J'ai essayé de les régler, mais il en reste un peu.

Le modèle est le suivant : 

$$
\mu \sim N(0, 5)\\
\sigma \sim N(0, 5) [\sigma > 0]\\
logit(p_1,p_2,...,p_K) \sim N(\mu,\sigma)\\
(x_1,x_2,...,x_K)\sim Binom((n_1,n_2,...,n_K),(p_1,p_2,...,p_K))
$$

Pour une raison qui m'échappe, la loi normale pour le paramètre de variance est meilleure que les autres distributions et donne moins de problèmes de convergence.

Dans la littérature, certains proposaient la loi de Cauchy, mais Gelmann est cité comme disant qu'une loi gamma ou une loi de Student tronquée positive est mieux adaptée.
Et on trouve aussi pas mal de loi normales tronquées.
En testant un peu, la loi normale donne moins de divergences.


## BOP2 en utilisant un modèle hiérarchique calibré pour la toxicité : "cbhmBOP"

Proposé par Chu et Yuan en 2018, l'idée est de mesurer le degré d'hétérogénéité entre les bras, et d'adapter le paramètre $\sigma$ du BHM en conséquence.
Ainsi, on estime un hyperparamètre de moins et c'est plus facile.
Une mesure classique d'hétérogénéité (et celle qui est prise ici) est la statistique du $\chi^2$.
Le fait de prendre une exponentielle pour la formule de la variance contraint des valeurs positives.

Les paramètres $a$ et $b$ ci-dessous sont calibrés par la procédure décrite dans l'article de Chu et Yuan.

Le modèle est le suivant : 

$$
\mu \sim N(0, 5)\\
\sigma^2 = e^{a+b\times\log(\text{Mesure d'hétérogénéité})}\\
logit(p_1,p_2,...,p_K) \sim N(\mu,\sigma)\\
(x_1,x_2,...,x_K)\sim Binom((n_1,n_2,...,n_K),(p_1,p_2,...,p_K))
$$


## BOP2 en analysant la toxicité par un modèle logistique : "bop_log1/2/3/4/5/6"

J'ai juste fait un modèle logistique simple avec comme seule covariable la dose.

J'ai testé plusieurs versions du modèle logistique :

1. modèle log-linéaire avec la dose : 
$$
\alpha\sim N(0,5)\\
\beta\sim N(0,5)\\
y\sim \text{Bernoulli}(expit(\alpha+\beta\times\text{Dose}))
$$
2. modèle log-linéaire avec la dose avec une pente positive : 
$$
\alpha\sim N(0,5)\\
\beta\sim N(0,5) ; \beta\geq0\\
y\sim \text{Bernoulli}(expit(\alpha+\beta\times\text{Dose}))
$$
3. modèle log-linéaire avec la dose avec un prior positif sur la pente : 
$$
\alpha\sim N(0,5)\\
\beta\sim N(0.5,5)\\
y\sim \text{Bernoulli}(expit(\alpha+\beta\times\text{Dose}))
$$
4. modèle avec la dose en catégoriel (on a 3 doses, et on les considère dans leur ordre croissant) : 
$$
\alpha\sim N(0,5)\\
\beta_1\sim N(0,5)\\
\beta_2\sim N(0,5)\\
y\sim \text{Bernoulli}(expit(\alpha+\beta_1\times\text{Dose}\in [2,3]+\beta_2\times\text{Dose}\in [3]))
$$
5. même modèle que le modèle 4, mais on force les coefficients à être positifs (hypothèse de la relation croissante avec la dose) : 
$$
\alpha\sim N(0,5)\\
\beta_1\sim N(0,5) ; \beta_1\geq0\\
\beta_2\sim N(0,5) ; \beta_2\geq0\\
y\sim \text{Bernoulli}(expit(\alpha+\beta_1\times\text{Dose}\in [2,3]+\beta_2\times\text{Dose}\in [3]))
$$
6. modèle reprenant la dose en variable continue avec un term quadratique pour autoriser des relations non linéaires : 
$$
\alpha\sim N(0,5)\\
\beta\sim N(0,5)\\
\gamma\sim N(0,5)\\
y\sim \text{Bernoulli}(expit(\alpha+\beta\times\text{Dose}+\gamma\times\text{Dose}^2))
$$


## Le modèle EXNEX : exnexBOP

C'est en principe un modèle intermédiaire entre la stratégie de faire un modèle dans chaque bras séparément et de faire un modèle hiérarchique.

On a une partie EX (exchangeable) qui est un modèle hiérarchique ; et une partie NEX (non-exchangeable) qui donne des priors faiblement informatifs pour chaque bras, et donc revient pratiquement à faire une analyse stratifiée.
Enfin, on fait une mixture de ces 2 distributions pour obtenir le modèle EXNEX :

$$
\theta_k|EX\sim N(\mu;\sigma)\\
\mu\sim N(-0.62,5)\\
\sigma\sim N(0,5)\\
\theta_k|NEX\sim N(-0.62;3)\\
\theta_k=\delta_k(\theta_k|EX)+(1-\delta_k)(\theta_k|NEX)\\
\delta_k\sim \text{Bernoulli}(0.5)\\
y_k\sim\text{Bernoulli}(expit(\theta_k))
$$

A noter, que les paramètres $theta$ sont centrés sur une valeur intermédiaire entre $H_0$ et $H_1$.



## Analyse jointe eff/tox

Aussi, j'ai testé d'appliquer les mêmes modèles à l'efficacité pour voir si ça donnait de meilleurs résultats.


# Paramètres de simulations

J'ai simulé 5000 essais pour évaluer chaque scénario pour chaque méthode.

Paramètres d'optimisation du seuil (comme pour mBOP de notre article) :

- FWER = 0.1
- 10 000 essais simulés pour évaluer le seuil, puis 5 000 essais par scénario
- Analyses d'efficacité et de toxicité à 15/30/45 patients
- 3 bras de traitement
- les bras seraient 3 doses d'Ibrutinib : 140, 280, et 420 mg/jour
- $H_0:\pi_{eff}=0.30 ; \pi_{tox}=0.40$ soit $(0.15;0.15;0.25;0.45)$ ($R=0.13$)
- $H_1:\pi_{eff}=0.50;\pi_{tox}=0.30$ soit $(0.20;0.30;0.10;0.40)$ ($R=0.22$)

J'ai pris 7 scénarios en respectant l'hypothèse que l'efficacité et la toxicité sont croissantes avec la dose, avec possiblement des plateaux.
Ils sont représentés sur l'image ci-dessous :

```{r img-sc}
include_graphics(here("Figures/scenar_simul_v3.png"))
```


J'ai essayé d'avoir les scénarios 1 et 2 qui sont des contrôles (tout $H_0$ ou tout $H_1$).
L'efficacité reste pareille pour les scénarios 3 à 7.

Scénario 3 : efficacité insuffisante qui monte d'intermédiaire vers désirable ; toxicité idem.
La toxicité monte avec un OR constant entre les doses.

Scénario 4 : idem que scénario 3 mais avec un OR non constant entre les doses.

Scénario 5 : la toxicité augmente entre une valeur faible et une valeur intermédiaire.
L'OR est constant.

Scénario 6 : idem que scénario 5 mais l'OR n'est pas constant.

Scénario 7 : toxicité avec plateau intermédiaire haut.

Au total, le bras 1 a une efficacité intermédiaire basse, le bras 2 avec une efficacité intermédiaire haute et une toxicité intermédiaire ou basse, et le bras 3 efficace et toxique/intermédiaire.

Les scénarios 8 à 12 sont pour une efficacité avec OR non constant.


# Résultats de la proportion de conclusion à un traitement prometteur

## Scénario 1

Ici tout les bras sont à l'hypothèse nulle.

```{r, fig.cap = "FWER pour le scénario 1"}
CaracGlobales %>% 
  filter(scenar %in% c("Sc1")) %>% 
  ggplot(aes(rejet_glob, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "FWER", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Référence", "Eff+Tox", "Tox")) +
  expand_limits(x = 0)
```

Le FWER est respecté pour mBOP.
Il est autour de 7% car même si c'est calibré pour maximum 10%, le FWER calibré est de 6.95%.

Le seqBOP est conservateur dans tous les cas, comme attendu.

La stratégie de power prior avec test augmente le FWER avec un seuil sur la Pvalue de 0.5 surtout quand on ajoute l'efficacité, et sinon reste comparable à mBOP.

Le modèle hiérarchique a un FWER comparable au mBOP, un peu plus faible.
Pour EXNEX et CBHM, il y a une légère inflation du FWER, mais sous le seuil des 10% prévus lorsqu'on analyse efficacité et toxicité.

Pour les modèles logistiques, on a le modèle 1 qui donne environ la même chose que mBOP, tout comme le modèle 6 (mais plus d'inflation du risque pour le modèle 6 dans le cas où on partage efficacité et toxicité).
Les modèles 5 et 2 donnent un schémas conservateur si on partage efficacité et toxicité ; et un schéma avec un risque d'erreur de type I augmenté si on n'applique le modèle que sur la toxicité.


```{r, fig.cap = "Proportion d'essai prometteurs dans chaque bras pour le scénario 1"}
CaracBras %>% 
  filter(scenar %in% c("Sc1")) %>% 
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "FWER", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Référence", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

Pour tBOP, hBOP, exnexBOP, cbhmBOP, boplog1 et 6, les performances sont voisines entre les bras et concordantes avec les caractéristiques globales.

Pour seqBOP, on mettant en place le partage d'information sur efficacité et toxicité, on est conservateur pareil dans les 3 bras, mais en ne la mettant que sur la toxicité, on est plus conservateur dans la bras 3 par rapport à 1, ce qui semble logique car dans le bras 1 on ne partage pas d'information alors que dans le bras 3, potentiellement on partage l'information des bras 1 et 2 s'ils s'arrêtent pour toxicité.

Enfin, pour boplog2 et 5, qui forcent une relation croissante avec la dose, en appliquant le modèle sur efficacité et toxicité, on a des résultats stables qui sont plus conservateurs que mBOP.
Et si on n'applique le modèle qu'à la toxicité, on est moins conservateur dans le bras 1 et plus dans le bras 3.
Forcer cette relation croissante semble faire croire au modèle que le bras 1 est peu toxique et le 3 l'est plus alors qu'en réalité, la toxicité est constante avec la dose.


## Scénario 2

On est ici dans le cas où tous les bras sont à l'hypothèse alternative.

```{r, fig.cap = "Puissance sous un scénario d'hypothèse alternative globale"}
CaracGlobales %>% 
  filter(scenar %in% c("Sc2")) %>% 
  ggplot(aes(rejet_glob, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "Puissance", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Référence", "Eff+Tox", "Tox")) +
  expand_limits(x = 0)
```

Globalement, sauf pour seqBOP qui est plus conservateur, on a une puissance qui est conservée.

```{r, fig.cap = "Puissance sous un scénario d'hypothèse alternative globale par bras"}
CaracBras %>% 
  filter(scenar %in% c("Sc2")) %>% 
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "Puissance", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Référence", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

Les résultats sont plus contrastés lorsqu'on regarde bras par bras.

Tout d'abord, seqBOP est un peu conservateur dans les bras 2 et surtout 3.

Pour les approches avec power prior, ainsi que pour hBOP, on semble être un peu plus puissant dans les bras.

Pour exnexBOP, cbhmBOP et boplog6, les résultats sont similaires avec mBOP, voire un peu plus puissant, mais pas de beaucoup.

Enfin, pour boplog1, on est similaire à mBOP sauf pour le bras 2 où on est plus puissant, sans que je sache bien ce qui se passe ; et boplog2 et 5 sont moins puissants pour les bras aux doses les plus élevés.


## Scénario 3

Le bras 1 est avec une efficacité intermédiaire et non toxique, le 2 juste à H1 pour l'efficacité avec une toxicité intermédiaire et le 3 toxique avec grande efficacité.

```{r, fig.cap = "Conclusion de traitement dans les bras du scénario 3"}
CaracBras %>% 
  filter(scenar %in% c("Sc3")) %>% 
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% conclusion de traitement prometteur", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Référence", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

En ce qui concerne seqBOP, il est surtout conservateur dans le bras 3.

exnexBOP, cbhmBOP et boplog6 sont globalement similaires à mBOP, avec plus de conclusion à des traitements prometteurs dans le bras 1 lorsqu'on applique le modèle à l'efficacité et la toxicité au lieu de juste la toxicité et sinon un peu plus de conclusion à un traitement prometteur globalement.
Pour ces modèles hiérarchiques, avec modèle sur l'efficacité et la toxicité, hBOP > cbhmBOP > exnexBOP  pour le pourcentage de conclusion à des traitements prometteurs.

Les power priors donnent plus de conclusions de traitements prometteurs dans les 3 bras, particulièrement dans les bras à dose élevée, sûrement à cause du fait qu'on partage de l'information de bras moins toxiques.
Et pour les bras à dose plus faible, le fait de prendre en compte l'efficacité dans le partage d'information augmente la proportion d'essais positifs, car on ajoute de l'information de bras efficaces, ce qui n'est pas le cas pour le cas où on ne prend en compte que la toxicité.

boplog1 est environ comme mBOP pour les bras 1 et 3, mais pour le 2, il donne plus d'essais positifs.
Pour la dose la plus élevée, c'est sûrement la toxicité qui prévaut sur la décision, et sur la dose intermédiaire, on a sûrement une estimation de l'efficacité un peu optimiste ou plus puissante que juste la loi beta, ce qui permet de plus dépasser le seuil.

Pour boplog2 et 5, on est très conservateur dans les bras à dose élevée et moins conservateurs dans les autres bras par rapport à mBOP.


## Scénario 4

C'est la même chose que le scénario 3 mais l'OR pour la toxicité n'est pas constant entre les doses et le bras 2 est plus toxique.

```{r, fig.cap = "Conclusion de traitement dans les bras du scénario 4"}
CaracBras %>% 
  filter(scenar %in% c("Sc4")) %>% 
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% conclusion de traitement prometteur", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Référence", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

On a une image similaire à ce qu'on avait avec le scénario 3.
Le mBOP donne un peu moins de conclusion à un traitement prometteur dans le bras 2, ce qui est logique vu qu'on a une toxicité un peu plus élevée.

Pour les bras 2 et 3, il y a un peu moins de conclusion de traitement prometteurs pour les techniques de partage d'information.
Même pour le bras 3 avec le partage d'informations du bras 2 qui est plus toxique.
Et pour boplog2 et 5, on a toujours le côté très conservateur pour le bras 3.


## Scénario 5

Contraitement aux scénarios 3 et 4, la toxicité va entre une valeur basse et une valeur intermédiaire.

```{r, fig.cap = "Conclusion de traitement prometteur dans les bras du scénario 5"}
CaracBras %>% 
  filter(scenar %in% c("Sc5")) %>% 
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% conclusion de traitement prometteur", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Référence", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

Comme pour tous les bras, on a seqBOP qui est plus conservateur pour le bras 3.
Comme on a une efficacité qui est assez bonne, on peut voir sur le tableau ci-dessous qu'il y a peu d'arrêt pour futilité dans les bras 2 et 3, ce qui explique la stabilité des résultats de seqBOP entre l'application uniquement sur la toxicité et l'application sur l'efficacité et la toxicité.

```{r}
CaracBras %>% 
  filter(methode == "seqBOP") %>% 
  select(scenar, cible, ttt, arret_fut) %>% 
  pivot_wider(names_from = "ttt", values_from = "arret_fut") %>% 
  flextable() %>% 
  autofit() %>% 
  theme_box() %>% 
  set_caption("Pourcentages d'arrêt des bras pour futilité dans chaque scénario")
```

Pour les stratégies de power prior, on a encore augmention du pourcentage de conclusion à un traitement prometteur.
Lorsqu'on ne partage l'information que sur la toxicité, cette augmentation est moindre pour les bras 1 et 2 car on partage de l'information de bras plus toxiques.

Pour le trio hBOP, cbhmBOP et exnexBOP, on a une légère augmentation de la proportion de conclusion à un traitement prometteur dans les 3 bras.
Il y a plus d'augmentation pour hBOP, et lorsqu'on applique les modèle à l'efficacité et la toxicité.
cbhmBOP et exnexBOP sont très proches avec un peu plus de conclusion à un traitement prometteur dans le bras 3 pour CBHM.

Enfin, pour les régressions logistiques, les modèles 2 et 5 sont toujours conservateurs pour le bras 3, et le modèle 6 est proche de mBOP tandis que le modèle 1 augmente un peu le pourcentage de conclusion à un traitement prometteur.


## Scénario 6

On a la même chose que le scénario 5 mais avec un OR non constant entre les doses pour la toxicité.

```{r, fig.cap = "Conclusion de traitement dans les bras du scénario 6"}
CaracBras %>% 
  filter(scenar %in% c("Sc6")) %>% 
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% conclusion de traitement prometteur", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Référence", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

On a des résultats très proches de ceux du scénarios 5.


## Scénario 7

La toxicité fait ici un plateau à une valeur intermédiaire entre $H_0$ et $H_1$ mais proche de $H_1$.

```{r, fig.cap = "Conclusion de traitement dans les bras du scénario 7"}
CaracBras %>% 
  filter(scenar %in% c("Sc7")) %>% 
  ggplot(aes(rejet_h0, methode, color = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% conclusion de traitement prometteur", y = NULL, color = "Variante") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Référence", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_wrap(vars(ttt))
```

On a ici des résultats très similaires au scénario 4 car on ne diffère que de quelques pourcents de toxicité pour le bras 3.


# Résumé par méthode

## seqBOP

Ici on a plutôt un effet à cause de la toxicité, mais le schéma, au niveau du FWER est plus conservateur, et est moins puissant.
A travers tous les scénarios, on a globalement une approche plus conservatrice pour le bras 3 surtout, et dans certains cas le bras 2 aussi.
Je pense que dans mes scénarios, on voit une différence pour le bras 3 car on a parfois des toxicités élevées dès le bras 2.
L'efficacité est déjà presque à $H_1$ dès le bras 2 donc ça doit expliquer le peu de différences entre quand on partage l'information pour efficacité + toxicité ou quand on ne partage que pour la toxicité.

Au total, on a un schéma qui est un peu moins puissant mais qui contrôle un peu mieux le risque de faux positifs.
En ouverture, on pourrait voir si optimiser le seuil en prenant en compte cela ne donnerait pas les mêmes résultats que le BOP2.

## tBOP

Peu importe le scénario, dans le cas où on partage l'information sur la toxicité et l'efficacité, on augmente le pourcentage de conclusion à un traitement prometteur.
Pour le partage de la toxicité seulement, dans les bras 1, on se rapproche un peu plus des résultats du mBOP.

Mais finalement, même avec un test pour partager l'information, cela donne de l'inflation du risque de faux positifs. 
Par exemple dans les bras 3, on a un traitement toxique dans les scénarios 1, 3 et 4, et pourtant on augmente le risque de faux positif.
Cette méthode n'a pas l'air faite pour ce qu'on souhaite faire.

## hBOP

Pour les scénarios 1 et 2, le modèle hiérarchique se débrouille bien avec un FWER conservé, et une meilleure puissance dans les bras.
En ne mettant un modèle hiérarchique que sur la toxicité, on observe moins d'augmentation de la proportion de conclusion à un traitement prometteur sur les bras 1 et 2, mais c'est sûrement dû au fait qu'on va partager l'information de bras toxiques donc on va peu faire tendre le résultat vers la non-toxicité, alors que si on incorpore l'efficacité, alors on peut faire tendre plus vers une conclusion de non-futilité car on partage l'information de bras efficaces.

En résumé, le modèle hiérarchique marche pas mal quand les doses ont des effets similaires.
Dans les autres cas, on augmente le pourcentage de conclusion à un traitement prometteur donc augmentation du risque de faux positif ainsi que de la puissance.

## cbhmBOP

Pour le CBHM, on a un FWER qui est légèrement augmenté mais reste sous les 10% nominaux.
Aussi, il y a augmentation de la puissance dans les bras, mais qui est intermédiaire par rapport au gain du modèle hiérarchique.
Dans le cas des autres scénarios, on a une augmentation modérée du pourcentage de conclusion à un traitement prometteur, plus élevé pour le bras 1, surtout si on partage l'information pour l'efficacité et la toxicité.

En résumé, le CBHM représente un bon compromis par rapport au modèle hiérarchique avec un moindre gain de puissance pour une moindre augmentation du risque de faux positifs.
En plus par rapport au modèle EXNEX, le modèle est plus facile à estimer et est peut-être donc plus stable, surtout avec moins de bras.

## exnexBOP

On a globalement les mêmes résultats que pour le CBHM.

## Modèles logistiques

Les modèles 2 et 5 ont des comportements qui sont indésirables dans le cas où on aurait un plateau.
Je pense que les modèles ont tendance à forcer une relation positive et pas juste nulle, ce qui fait qu'alors même qu'on a la même toxicité dans les bras, le modèle va considérer que la dose la plus élevée est plus toxique.

Concernant les autres modèles, le modèle 6 qui introduit une relation quadratique donne environ les mêmes résultats que mBOP.
Avec 3 paramètres pour le modèle logistique, j'ai l'impression que cela revient à estimer un intercept et un coefficient par dummy variable. 
Du coup, avec 3 doses, je pense que c'est comme si on faisait l'estimation dans chaque bras et on se retrouve avec les mêmes résultats que mBOP.
Et pour le modèle 1, on a un FWER voisin de celui de mBOP avec une puissance par bras qui est légèrement augmentée.
Globalement, dans les résultats, j'ai l'impression qu'il favorisait plus le bras 2 et donc peut-être qu'il laisse plus passer les bras intermédiaires.
En remarque, il ne semble pas y avoir trop de perte avec l'hypothèse de log-linéarité.


# Supplément : les autres caractéristiques opérationnelles

## Le nombre moyen de patients

```{r}
CaracBrasSup <- CaracBras %>% 
  bind_rows(CaracBras %>% filter(methode %in% "mBOP") %>% mutate(cible = "tox")) %>% 
  mutate(cible = ifelse(cible == "both", "efftox", cible))
```


```{r, fig.width = 10, fig.height = 16}
CaracBrasSup %>% 
  filter(scenar %in% paste0("Sc", 1:7)) %>% 
  mutate(scenar = factor(scenar, levels = paste0("Sc", 1:7))) %>% 
  ggplot(aes(x = tot_pat, y = methode, fill = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 7.5, ymax = 8.5, fill = "darkgrey", alpha = .6) +
  geom_col(position = position_dodge(width = 1)) +
  facet_grid(scenar ~ cible)
```

La zone grisée correspond à mBOP pour faciliter les comparaisons.

Pour boplog2 et 5, on a la réduction du nombre moyens de patients pour le bras 3 lorsqu'on n'applique le modèle que pour la toxicité, et pour les bras 1 et 3 lorsqu'on l'applique à l'efficacité et la toxicité.
Cela concorde avec l'observation que ces modèles sont conservateurs pour leurs extrêmes (dose élevée pour la toxicité et faible pour l'efficacité).

seqBOP a l'air très comparable à mBOP de façon assez surprenante.

tBOP a environ autant de patients avec un seuil de 0.5 et plus de patients pour un seuil de 0.1.
Pour le seuil de 0.1, cela va de paire avec l'augmentation des conclusions à des traitements prometteurs.

Les modèles hBOP, cbhmBOP et exnexBOP recrutent moins de patients sous $H_0$ et un peu plus de patients sous $H_1$.
Pour les autres scénarios, le hBOP recrute un peu plus de patients ; le cbhmBOP et exnexBOP ont l'air d'inclure environ autant de patients que mBOP en moyenne, peut-être un peu moins pour CBHM.

Malgré le pourcentage de conclusion proche de mBOP, boplog6 semble recruter un peu plus de patients, mais pas forcément avec plus d'arrêt précoces en inspectant visuellement le tableau.
Peut-être ce sont des arrêts précoces à une analyse intermédiaire ultérieure.

boplog1 favorise le bras 2 en allouant plus de patients, et donne moins de patients dans les bras 1 et 3.

## Scénarios 8 à 12

```{r, fig.width = 10, fig.height = 16}
CaracBras$eff_forme <- "OR constant"
CaracBras$eff_forme[CaracBras$scenar %in% paste0("Sc", 8:12)] <- "OR non constant"
CaracBras$scenar[CaracBras$scenar %in% paste0("Sc", 8:12)] <- paste0("Sc", as.numeric(gsub("^Sc(\\d+)$", "\\1", CaracBras$scenar[CaracBras$scenar %in% paste0("Sc", 8:12)])) - 5)
CaracBras %>% 
  filter(!scenar %in% c("Sc1", "Sc2")) %>% 
  ggplot(aes(rejet_h0, methode, color = cible, shape = eff_forme, group = cible)) +
  geom_point(position = position_dodge(width = .5), size = 2) +
  labs(x = "% conclusion de traitement prometteur", y = NULL, color = "Variante", shape = "Forme d'efficacité") +
  scale_color_discrete(type = c("black", "steelblue", "coral"), labels = c("Référence", "Eff+Tox", "Tox")) +
  expand_limits(x = 0) +
  facet_grid(scenar ~ ttt)
```

Globalement, pour le bras 3 il n'y a pas d'influence.

Pour le bras 1, les modèles logistiques ont une petite influence avec une proportion de conclusion à un traitement prometteur un peu moins importante en cas d'OR constant pour l'efficacité entre les doses.

Pour le bras 2, tous les modèles ont la même influence.

Le fait de modéliser en même temps efficacité et toxicité diminue l'impact de la relation non log-linéaire.

## Estimation de l'efficacité

```{r}
Scenarios <- list(
  Sc1 = list(ttt1 = c(0.15, 0.15, 0.25, 0.45), ttt2 = c(0.15, 0.15, 0.25, 0.45), ttt3 = c(0.15, 0.15, 0.25, 0.45)),
  Sc2 = list(ttt1 = c(0.20, 0.30, 0.10, 0.40), ttt2 = c(0.20, 0.30, 0.10, 0.40), ttt3 = c(0.20, 0.30, 0.10, 0.40)),
  Sc3 = list(ttt1 = c(0.15, 0.20, 0.15, 0.50), ttt2 = c(0.19, 0.23, 0.16, 0.42), ttt3 = c(0.25, 0.25, 0.15, 0.35)),
  Sc4 = list(ttt1 = c(0.15, 0.20, 0.15, 0.50), ttt2 = c(0.20, 0.22, 0.18, 0.40), ttt3 = c(0.25, 0.25, 0.15, 0.35)),
  Sc5 = list(ttt1 = c(0.13, 0.22, 0.15, 0.50), ttt2 = c(0.16, 0.26, 0.15, 0.43), ttt3 = c(0.20, 0.30, 0.15, 0.35)),
  Sc6 = list(ttt1 = c(0.13, 0.22, 0.15, 0.50), ttt2 = c(0.18, 0.24, 0.15, 0.43), ttt3 = c(0.20, 0.30, 0.15, 0.35)),
  Sc7 = list(ttt1 = c(0.15, 0.20, 0.15, 0.50), ttt2 = c(0.20, 0.22, 0.18, 0.40), ttt3 = c(0.22, 0.28, 0.16, 0.34)),
  Sc8 = list(ttt1 = c(0.15, 0.20, 0.15, 0.50), ttt2 = c(0.20, 0.25, 0.15, 0.40), ttt3 = c(0.25, 0.25, 0.15, 0.35)),
  Sc9 = list(ttt1 = c(0.15, 0.20, 0.15, 0.50), ttt2 = c(0.20, 0.25, 0.18, 0.37), ttt3 = c(0.25, 0.25, 0.15, 0.35)),
  Sc10 = list(ttt1 = c(0.13, 0.22, 0.15, 0.50), ttt2 = c(0.18, 0.27, 0.13, 0.42), ttt3 = c(0.20, 0.30, 0.15, 0.35)),
  Sc11 = list(ttt1 = c(0.13, 0.22, 0.15, 0.50), ttt2 = c(0.18, 0.27, 0.15, 0.40), ttt3 = c(0.20, 0.30, 0.15, 0.35)),
  Sc12 = list(ttt1 = c(0.15, 0.20, 0.15, 0.50), ttt2 = c(0.20, 0.25, 0.18, 0.37), ttt3 = c(0.22, 0.28, 0.16, 0.34))
)
TabScenars <- do.call("rbind", lapply(names(Scenarios), \(nom_scenar) {
  do.call("rbind", lapply(names(Scenarios[[nom_scenar]]), \(nom_bras) {
    VecProba <- Scenarios[[nom_scenar]][[nom_bras]]
    data.frame("scenar" = nom_scenar, "ttt" = nom_bras, "eff_true" = VecProba[1] + VecProba[2], "tox_true" = VecProba[1] + VecProba[3])
  }))
}))
CaracEssaisSup <- CaracEssais %>% 
  bind_rows(CaracEssais %>% filter(methode %in% "mBOP") %>% mutate(cible = "tox")) %>% 
  mutate(cible = ifelse(cible == "both", "efftox", cible))
```


```{r, fig.width = 12, fig.height = 20}
left_join(CaracEssaisSup, TabScenars, by = join_by(scenar, ttt)) %>% 
  group_by(scenar, ttt, methode, cible) %>% 
  summarise(biais_eff = mean(est_eff - eff_true), .groups = "drop") %>% 
  filter(scenar %in% paste0("Sc", 1:7)) %>% 
  ggplot(aes(biais_eff, methode, fill = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 7.5, ymax = 8.5, fill = "darkgrey", alpha = .6) +
  geom_hline(yintercept = seq(1.5, 10.5), linetype = "dashed", color = "darkgrey", linewidth = 1) +
  geom_col(position = position_dodge(width = 1)) +
  facet_grid(scenar ~ cible) +
  scale_x_continuous(labels = scales::percent_format()) +
  labs(x = "Biais dans l'estimation de l'efficacité")
```

Sur le côté droit, comme on n'applique le modèle qu'à la toxicité, on ne voit pas grand chose.
Globalement, on sous-estime la valeur d'efficacité, ce qui est attendu car on peut s'arrêter pour futilité, ce qui biaise l'estimation vers le bas.

Sur le côté gauche, ce qui saute aux yeux c'est que les modèles log2 et log5 sont très biaisés : sous-estimation dans le bras 1 et surestimation dans le bras 3, probablement provoqué par la contrainte d'une relation croissante avec la dose.
seqBOP donne environ la même estimation que mBOP ou un peu plus conservateur.
Les power priors peuvent donner des biais dans les 2 sens selon le scénario d'amplitude comparable à mBOP pour le seuil de 0.5 et plus importante pour le seuil de 0.1.
Le modèle hiérarchique, en ramenant l'estimation vers la moyenne commune aux 3 bras, peut donner des biais dans les 2 sens (surestimation pour les faibles doses et sous-estimation pour les fortes doses), dans un ordre de grandeur qui est comparable à mBOP.
Les modèles CBHM et EXNEX sont quant à eux moins biaisés que mBOP.
Idem pour boplog1 et boplog6.

```{r, fig.width = 12, fig.height = 20}
CaracEssaisSup %>% 
  mutate(larg_ic = icsup_eff - icinf_eff) %>% 
  group_by(scenar, ttt, methode, cible) %>% 
  summarise(moy = mean(larg_ic), 
            perc5 = quantile(larg_ic, probs = .05), 
            perc2_5 = quantile(larg_ic, probs = .025), 
            perc95 = quantile(larg_ic, probs = .95), 
            perc97_5 = quantile(larg_ic, probs = .975), 
            .groups = "drop") %>% 
  filter(scenar %in% paste0("Sc", 1:7)) %>%
  ggplot(aes(y = methode, color = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 7.5, ymax = 8.5, fill = "darkgrey", alpha = .6) +
  geom_hline(yintercept = seq(1.5, 10.5), linetype = "dashed", color = "darkgrey", linewidth = 1) +
  geom_point(aes(x = moy), position = position_dodge(width = 1)) +
  geom_segment(aes(x = perc2_5, xend = perc97_5), position = position_dodge(width = 1)) +
  facet_grid(scenar ~ cible) +
  scale_x_continuous(labels = scales::percent_format()) +
  labs(x = "Largeur de l'IC de l'efficacité", caption = "Le point est la moyenne et le trait va du 2.5ème percentile au 97.5ème percentile dans les 5000 essais simulés")
```

On se concentre encore sur le panel de gauche.

Pour seqBOP, l'IC est un peu moins large pour les doses faibles, ce qui coincide avec le partage d'information des bras à une dose supérieure qui serait non efficace, sauf pour le scénario 2 car peu de bras qui sont étiquetés non efficaces.
Les power priors sont un peu moins large que mBOP.
Parmi les 3 modèles bayésiens hiérarchiques, le hBOP donne les IC les plus étroits, exnexBOP et cbhmBOP ont environ la même largeur de l'IC, mais cbhmBOP peut être plus large, même plus que mBOP.
boplog2 et 5 ont des IC plus étroits.
Cela semble logique du fait qu'on ajoute des contraintes qui diminuent la variabilité de ce qu'on estime.
boplog6 est environ comme mBOP.
boplog1 a des IC plus étroits pour le bras 2, et pour les autres bras, soit environ comme mBOP, soit un peu plus étroits.


## Estimation de la toxicité


```{r, fig.width = 12, fig.height = 20}
left_join(CaracEssaisSup, TabScenars, by = join_by(scenar, ttt)) %>% 
  group_by(scenar, ttt, methode, cible) %>% 
  summarise(biais_tox = mean(est_tox - tox_true), .groups = "drop") %>% 
  filter(scenar %in% paste0("Sc", 1:7)) %>% 
  ggplot(aes(biais_tox, methode, fill = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 7.5, ymax = 8.5, fill = "darkgrey", alpha = .6) +
  geom_hline(yintercept = seq(1.5, 10.5), linetype = "dashed", color = "darkgrey", linewidth = 1) +
  geom_col(position = position_dodge(width = 1)) +
  facet_grid(scenar ~ cible) +
  scale_x_continuous(labels = scales::percent_format()) +
  labs(x = "Biais dans l'estimation de la toxicité")
```

Pour la toxicité, on a tendance à être biaisé vers une surrestimation de la toxicité de manière générale, ce qui va dans le sens de l'analyse : comme on arrête les bras trop toxiques, il y a des chances qu'on sélectionne des moments/des bras qui sont plus toxiques pour leur dernière analyse.

Les 2 panels sont comparables.

On remarque d'emblée qu'il y a des gros biais pour boplog5 et 2 avec une surestimation de la toxicité pour la dose la plus élevée, et une sous-estimation pour la dose la plus faible. 
C'est certainement dû à la contrainte d'une relation positive avec la dose.
seqBOP, tout comme pour l'efficacité est plus conservateur.
Pour le power prior, dans le cas du seuil à 0.5, l'estimation de la toxicité est plus conservatrice que pour mBOP, et dans le cas du seuil à 0.1, cela peut aller dans les 2 sens.
Parmi les modèles hiérarchiques, cette fois-ci, il ne semble pas y avoir de résultat biaisé vers une sous-estimation, mais selon les scénarios c'est peut-être possible.
Le modèle hBOP est celui qui donne le moins de biais.
Enfin, boplog6 et boplog1 font environ comme mBOP, avec parfois un peu plus de biais que mBOP.

```{r, fig.width = 12, fig.height = 20}
CaracEssaisSup %>% 
  mutate(larg_ic = icsup_tox - icinf_tox) %>% 
  group_by(scenar, ttt, methode, cible) %>% 
  summarise(moy = mean(larg_ic), 
            perc5 = quantile(larg_ic, probs = .05), 
            perc2_5 = quantile(larg_ic, probs = .025), 
            perc95 = quantile(larg_ic, probs = .95), 
            perc97_5 = quantile(larg_ic, probs = .975), 
            .groups = "drop") %>% 
  filter(scenar %in% paste0("Sc", 1:7)) %>%
  ggplot(aes(y = methode, color = ttt)) +
  annotate("ribbon", x = c(-Inf, Inf), ymin = 7.5, ymax = 8.5, fill = "darkgrey", alpha = .6) +
  geom_hline(yintercept = seq(1.5, 10.5), linetype = "dashed", color = "darkgrey", linewidth = 1) +
  geom_point(aes(x = moy), position = position_dodge(width = 1)) +
  geom_segment(aes(x = perc2_5, xend = perc97_5), position = position_dodge(width = 1)) +
  facet_grid(scenar ~ cible) +
  scale_x_continuous(labels = scales::percent_format()) +
  labs(x = "Largeur de l'IC de la toxicité", caption = "Le point est la moyenne et le trait va du 2.5ème percentile au 97.5ème percentile dans les 5000 essais simulés")
```

seqBOP a des IC plus étroits lorsqu'on va vers les doses les plus élevées lié au partage d'information des bras à une dose plus faibles qui sont toxiques.
Les powers priors donnent des IC plus étroits que mBOP, encore plus lorsque le seuil est faible car on partage plus souvent de l'information.
Pour les modèles hiérarchiques, tout comme pour l'efficacité, hBOP donne les IC les plus étroits, cbhmBOP un peu plus étroit que mBOP, et exnexBOP qui donne environ la même largeur que mBOP.
Pour les modèles logistiques, les modèles 2 et 5 donnent des IC plus étroits, tandis que le modèle 1 donne des IC plus étroits pour le bras 2.


